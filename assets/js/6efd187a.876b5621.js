"use strict";(self.webpackChunkcka_prep_2=self.webpackChunkcka_prep_2||[]).push([[1400],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),d=u(n),m=l,k=d["".concat(s,".").concat(m)]||d[m]||c[m]||o;return n?a.createElement(k,r(r({ref:t},p),{},{components:n})):a.createElement(k,r({ref:t},p))}));function m(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var o=n.length,r=new Array(o);r[0]=d;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:l,r[1]=i;for(var u=2;u<o;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},5812:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return p},default:function(){return d}});var a=n(7462),l=n(3366),o=(n(7294),n(3905)),r=["components"],i={id:"chapter03",title:"Installation and Configuration"},s=void 0,u={unversionedId:"fundamentals/chapter03",id:"fundamentals/chapter03",title:"Installation and Configuration",description:"Course Reading",source:"@site/docs/fundamentals/chapter03.md",sourceDirName:"fundamentals",slug:"/fundamentals/chapter03",permalink:"/cka-prep/docs/fundamentals/chapter03",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/fundamentals/chapter03.md",tags:[],version:"current",frontMatter:{id:"chapter03",title:"Installation and Configuration"},sidebar:"tutorialSidebar",previous:{title:"Basics of Kubernetes",permalink:"/cka-prep/docs/fundamentals/chapter02"},next:{title:"Kubernetes Architecture",permalink:"/cka-prep/docs/fundamentals/chapter04"}},p=[{value:"Course Reading",id:"course-reading",children:[{value:"Learning objectives",id:"learning-objectives",children:[],level:3},{value:"Installation tools",id:"installation-tools",children:[],level:3},{value:"Installing <code>kubectl</code>",id:"installing-kubectl",children:[],level:3},{value:"Using Google Kubernetes Engine (GKE)",id:"using-google-kubernetes-engine-gke",children:[],level:3},{value:"Using minikube",id:"using-minikube",children:[],level:3},{value:"Installing with <code>kubeadm</code>",id:"installing-with-kubeadm",children:[],level:3},{value:"<code>kubeadm-upgrade</code>",id:"kubeadm-upgrade",children:[],level:3},{value:"Installing a Pod network",id:"installing-a-pod-network",children:[{value:"Calico",id:"calico",children:[],level:4},{value:"Flannel",id:"flannel",children:[],level:4},{value:"Kube-Router",id:"kube-router",children:[],level:4},{value:"Romana",id:"romana",children:[],level:4},{value:"Weave Net",id:"weave-net",children:[],level:4}],level:3},{value:"More installation tools",id:"more-installation-tools",children:[{value:"kubespray",id:"kubespray",children:[],level:4},{value:"kops",id:"kops",children:[],level:4},{value:"kube-aws",id:"kube-aws",children:[],level:4},{value:"kubicorn",id:"kubicorn",children:[],level:4}],level:3},{value:"Installation considerations",id:"installation-considerations",children:[],level:3},{value:"Main deployment configurations",id:"main-deployment-configurations",children:[],level:3},{value:"<code>systemd</code> unit file for Kubernetes",id:"systemd-unit-file-for-kubernetes",children:[],level:3},{value:"Using Hyperkube",id:"using-hyperkube",children:[],level:3},{value:"Compiling from source",id:"compiling-from-source",children:[],level:3}],level:2},{value:"Lab Exercises",id:"lab-exercises",children:[{value:"Lab 3.1 - Install Kubernetes",id:"lab-31---install-kubernetes",children:[],level:3},{value:"Lab 3.2 - Grow the cluster",id:"lab-32---grow-the-cluster",children:[],level:3},{value:"Lab 3.3 - Finish cluster setup",id:"lab-33---finish-cluster-setup",children:[],level:3},{value:"Lab 3.4 - Deploy a simple application",id:"lab-34---deploy-a-simple-application",children:[],level:3},{value:"Lab 3.5 - Access from outside the cluster",id:"lab-35---access-from-outside-the-cluster",children:[],level:3}],level:2},{value:"Knowledge check",id:"knowledge-check",children:[],level:2}],c={toc:p};function d(e){var t=e.components,i=(0,l.Z)(e,r);return(0,o.kt)("wrapper",(0,a.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"course-reading"},"Course Reading"),(0,o.kt)("h3",{id:"learning-objectives"},"Learning objectives"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Download installation and configuration tools"),(0,o.kt)("li",{parentName:"ul"},"Install a Kubernetes master and grow cluster"),(0,o.kt)("li",{parentName:"ul"},"Configure network for secure communication"),(0,o.kt)("li",{parentName:"ul"},"High-availability deployment considerations")),(0,o.kt)("h3",{id:"installation-tools"},"Installation tools"),(0,o.kt)("p",null,"There are many ways to get up an running with Kubernetes."),(0,o.kt)("p",null,"If you want to get started without needing to install and configure the cluster yourself, a managed cloud provider solution is a good option.  Google offers ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/kubernetes-engine"},"Google Kubernetes Engine")," (GKE) and AWS offers ",(0,o.kt)("a",{parentName:"p",href:"https://aws.amazon.com/eks/"},"Elastic Kubernetes Service")," (EKS) which gives users more control of cp nodes."),(0,o.kt)("p",null,"Another simple way to get up and running is with ",(0,o.kt)("a",{parentName:"p",href:"https://minikube.sigs.k8s.io/docs/"},"Minikube")," which is a single binary that runs in a VirtualBox VM.  This is a great tool to use as a learning and testing environment even though it is just a single node."),(0,o.kt)("p",null,"Canonical has also developed a tool called ",(0,o.kt)("a",{parentName:"p",href:"https://microk8s.io/docs"},"MicroK8s")," which aims to make installation easy.  This is great for running Kubernetes at the edge or on IoT devices. Runs on Ubuntu 16.04 and later."),(0,o.kt)("p",null,"This course focuses on using ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," which is the suggested community tool by the Kubernetes project for setting up a cluster.  Getting the cluster set up with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," only requires two commands, ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm init")," on the cp node and ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm join")," on any worker nodes or additional cp nodes, and the cluster bootstraps itself."),(0,o.kt)("p",null,"To actually use the cluster the ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," command is used.  This run locally on your machine and communicated with the cluster API endpoint.  ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," can control all Kubernetes resources to create, manage, and delete."),(0,o.kt)("p",null,"There are also other mechanisms to create a Kubernetes cluster, like ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/kubespray"},"kubespray")," and ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/kops"},"kops"),"."),(0,o.kt)("h3",{id:"installing-kubectl"},"Installing ",(0,o.kt)("inlineCode",{parentName:"h3"},"kubectl")),(0,o.kt)("p",null,"The recommended way to configure and manage your Kubernetes cluster is ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl"),".  Most distros have ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," available in their repositories, or you can download the code from ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/kubernetes/tree/master/pkg/kubectl"},"Github")," and compile and install from the source code."),(0,o.kt)("p",null,"The command stores its configuration in ",(0,o.kt)("inlineCode",{parentName:"p"},"$HOME/.kube/config"),", which contains information for all the K8s endpoints you might use.  In it are cluster definitions (IP endpoints), credentials, and contexts.  The contexts is a combination of cluster and user credentials, which can be passed in the command line or the context can be switched with "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl config use-context foobar\n")),(0,o.kt)("p",null,"which is helpful for switching between local environments to a cluster in the cloud."),(0,o.kt)("h3",{id:"using-google-kubernetes-engine-gke"},"Using Google Kubernetes Engine (GKE)"),(0,o.kt)("p",null,"Requirements:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"A Google Cloud account"),(0,o.kt)("li",{parentName:"ul"},"Payment method for any services used"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"gcloud")," command line client.")),(0,o.kt)("p",null,"Instructions for installing ",(0,o.kt)("inlineCode",{parentName:"p"},"gcloud")," can be found ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/sdk/docs/install#linux"},"here"),"."),(0,o.kt)("p",null,"The GKE quick start guide can be found ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/kubernetes-engine/docs/quickstart"},"here"),"."),(0,o.kt)("p",null,"Then to create your first cluster in GKE:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters create linuxfoundation\n\ngcloud container clusters list\n\nkubectl get nodes\n")),(0,o.kt)("p",null,"The first command creates the cluster with the name ",(0,o.kt)("em",{parentName:"p"},"linuxfoundation"),".  The next command lists the cluster. The final command lists the nodes of the cluster. Installing ",(0,o.kt)("inlineCode",{parentName:"p"},"gcloud")," automatically installs ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," as well."),(0,o.kt)("p",null,"Once done with the cluster, ",(0,o.kt)("strong",{parentName:"p"},"delete it or you will be charged"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters delete linuxfoundation\n")),(0,o.kt)("h3",{id:"using-minikube"},"Using minikube"),(0,o.kt)("p",null,"Minikube is a project under the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/minikube"},"Kubernetes organization on Github"),"."),(0,o.kt)("p",null,"To download and install the latest version of minikube run"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64\n\nchmod +x minikube\n\nsudo mv minikube /usr/local/bin\n")),(0,o.kt)("p",null,"Once minikube is installed, the Kubernetes can be started with"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"minikube start\n\nkubectl get nodes\n")),(0,o.kt)("p",null,"The first command will start a VirtualBox VM running a single node Kubernetes deployment and the Docker engine.  Internally, minikube is running a single Golang binary, ",(0,o.kt)("inlineCode",{parentName:"p"},"localkube"),", which runs all the components on Kubernetes together, which makes minikube much simpler than a full Kubernetes deployment."),(0,o.kt)("h3",{id:"installing-with-kubeadm"},"Installing with ",(0,o.kt)("inlineCode",{parentName:"h3"},"kubeadm")),(0,o.kt)("p",null,"Currently, the most straightforward method of building a full Kubernetes cluster is ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," which was first introduced in v1.4.0 and moved from beta to stable with added functionality for high availability in v1.15.0."),(0,o.kt)("p",null,"Official documentation for setting up a cluster with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," can be found ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/"},"here"),"."),(0,o.kt)("p",null,"To setup a cluster:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Run ",(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm init")," on head node"),(0,o.kt)("li",{parentName:"ul"},"Create network for IP-per-Pod criteria"),(0,o.kt)("li",{parentName:"ul"},"Run ",(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm join")," on workers or secondary cp nodes.")),(0,o.kt)("p",null,"Joining other nodes to the cluster will require at least a token and a SHA256 hash, which is returned by the ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm init"),". ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl")," can also be used to create the network using a resource manifest."),(0,o.kt)("p",null,"An example, using the Weave network:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f https://git.io/weave-kube\n")),(0,o.kt)("p",null,"Once the steps are complete and the workers and secondary cp nodes have joined, there will be an operational multi-node Kubernetes cluster and you can interact with it using ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl"),"."),(0,o.kt)("h3",{id:"kubeadm-upgrade"},(0,o.kt)("inlineCode",{parentName:"h3"},"kubeadm-upgrade")),(0,o.kt)("p",null,"Building the cluster with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," gives the option to upgrade using ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm upgrade"),".  Most users will try to stay on the same version for as long as possible, but this tool allows a path for regular upgrades for security."),(0,o.kt)("p",null,"Some of the command for ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm upgrade"),":"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"plan")," checks the installed version against the newest version to verify upgradeability"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"apply")," upgrades the first cp node to the version specified"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"diff")," shows the differences applied in an upgrade. It is similar to ",(0,o.kt)("inlineCode",{parentName:"li"},"apply --dry-run"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"node")," lets local kubelet configuration to be updated on the worker nodes, or secondary cp nodes. Also calls a ",(0,o.kt)("inlineCode",{parentName:"li"},"phase")," command to step through upgrading.")),(0,o.kt)("p",null,"In general, the process for upgrading is:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Update software"),(0,o.kt)("li",{parentName:"ul"},"Check version"),(0,o.kt)("li",{parentName:"ul"},"Drain cp"),(0,o.kt)("li",{parentName:"ul"},"View planned upgrade"),(0,o.kt)("li",{parentName:"ul"},"Apply upgrade"),(0,o.kt)("li",{parentName:"ul"},"Uncordon the cp and allow pods to be scheduled")),(0,o.kt)("p",null,"More in-depth documentation about the upgrade process can be found in the ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/"},"official documentation here"),"."),(0,o.kt)("h3",{id:"installing-a-pod-network"},"Installing a Pod network"),(0,o.kt)("p",null,"Prior to initialization of a cluster, a network needs to be considered and IP conflicts avoided.  There are many options for Pod networking. Many projects mention Container Network Interface (or CNI, another CNCF project) as a way to handle deployments and cleaning up network resources."),(0,o.kt)("h4",{id:"calico"},"Calico"),(0,o.kt)("p",null,"A flat layer 3 network that communicates without IP encapsulation. It is used in production with many orchestration tools.  It has a simple and flexible networking model and scales well to large environments.  Canal is another option, that is part of the same project, which can integrate with Flannel.  Calico also allows implementing network policies.  "),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.tigera.io/project-calico/"},"Project webpage")),(0,o.kt)("h4",{id:"flannel"},"Flannel"),(0,o.kt)("p",null,"A layer 3 IPv4 network between cluster nodes. It has a long history with Kubernetes as it as developed by CoreOS.  Flannel focuses on traffic between hosts, not the local container configuration for networking. ",(0,o.kt)("inlineCode",{parentName:"p"},"flanneld")," agents sit on each node to allocate subnet leases to the host.  It can be configured after deployment but it is easier before Pods are added."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/flannel-io/flannel"},"Project Github")),(0,o.kt)("h4",{id:"kube-router"},"Kube-Router"),(0,o.kt)("p",null,'A single binary that "',(0,o.kt)("em",{parentName:"p"},"does it all"),'".  It is in alpha but promises distributed load balancer, firewall, and router purpose built for K8s.'),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.kube-router.io/"},"Project webpage")),(0,o.kt)("h4",{id:"romana"},"Romana"),(0,o.kt)("p",null,"This project is aimed towards automating network and security in cloud native applications.  Romana is aimed at large clusters, IPAM-aware topology and integrates with kops clusters."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/romana/romana"},"Project Github")),(0,o.kt)("h4",{id:"weave-net"},"Weave Net"),(0,o.kt)("p",null,"Usually used as an add-on for CNI enabled clusters."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.weave.works/oss/net/"},"Project webpage")),(0,o.kt)("h3",{id:"more-installation-tools"},"More installation tools"),(0,o.kt)("p",null,"Kubernetes is like any other application you would install on a server so the the usual configuration management tools (Terraform, Ansible, Chef, Puppet, etc.) can be used for installation."),(0,o.kt)("p",null,"The best way to learn about installing Kubernetes manually is with Kelsey Hightower's ",(0,o.kt)("a",{parentName:"p",href:"../hard-way/about"},"Kubernetes the Hard Way"),"."),(0,o.kt)("h4",{id:"kubespray"},"kubespray"),(0,o.kt)("p",null,"kubespray is a Kubernetes incubator project. It is an advanced ansible playbook that can set up a cluster on different OSes with different network providers.  It was formerly known as kargo."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/kubespray"},"Project Github")),(0,o.kt)("h4",{id:"kops"},"kops"),(0,o.kt)("p",null,"kops (short for Kubernetes Operations) allows for single command line creation of K8s cluster on AWS.  Creation on GKE is in beta and VMWare is in alpha."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/kops"},"Project Github")),(0,o.kt)("h4",{id:"kube-aws"},"kube-aws"),(0,o.kt)("p",null,"A command line tool for creating Kubernetes clusters on AWS using CloudFormation.  This tool has been retired and has reached end of life."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-retired/kube-aws"},"Project Github")),(0,o.kt)("h4",{id:"kubicorn"},"kubicorn"),(0,o.kt)("p",null,"kubicorn leverages kubeadm to build clusters.  It has no DNS dependency, runs on multiple OSes, and uses snapshots to capture clusters and move them."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"http://kubicorn.io/"},"Project Github")),(0,o.kt)("h3",{id:"installation-considerations"},"Installation considerations"),(0,o.kt)("p",null,"Before installing a full cluster, it is good to experiment with a single node cluster, like the one minikube provides."),(0,o.kt)("p",null,"Once ready to deploy a cluster of servers there are a some decision points"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"What provider? Public or private cloud? Virtual or physical servers?"),(0,o.kt)("li",{parentName:"ul"},"What operating system? Kubernetes runs on most Linux distros."),(0,o.kt)("li",{parentName:"ul"},"What networking solution? Is an overlay needed?"),(0,o.kt)("li",{parentName:"ul"},"High availability for the head nodes?")),(0,o.kt)("p",null,"To choose the best option, the Kubernetes ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/setup/"},(0,o.kt)("em",{parentName:"a"},"Getting Started"))," docs are a good resource."),(0,o.kt)("p",null,"In most cases the Kubernetes components will run as ",(0,o.kt)("inlineCode",{parentName:"p"},"systemd")," unit files as that has become the dominant init system for Linux OSes.  They could also be run by a kubelet on the head node (kubeadm)."),(0,o.kt)("h3",{id:"main-deployment-configurations"},"Main deployment configurations"),(0,o.kt)("p",null,"There are four main deployment configurations."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Single node")," - all components run on the same server, Good for testing and development, not well suited for production."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Single head node, multiple workers")," - Typically has an etcd instance running on the head node with the API, scheduler, and controller-manager."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Multiple head nodes with HA, multiple workers")," - This type of configuration adds more durability to the cluster. The API server is fronted by a load balancer, scheduler and controller-manager elect a leader (configured by flags). etcd can still run as a single node."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"HA etcd, HA head nodes, multiple workers")," - This is the most advanced and robust Kubernetes setup.  etcd would also run as a true cluster on nodes separate from th head nodes.")),(0,o.kt)("p",null,"A tool called Kubernetes Federation also offers high availability.  It joins multiple clusters together with a common cp to let resources move between clusters administratively or due to failure.  It has some issues but there is hope ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/kubefed"},"v2")," will be a better product."),(0,o.kt)("h3",{id:"systemd-unit-file-for-kubernetes"},(0,o.kt)("inlineCode",{parentName:"h3"},"systemd")," unit file for Kubernetes"),(0,o.kt)("p",null,"In any of the mentioned configurations, some components will run as standard system daemons. Here is an example of a (by no means perfect) ",(0,o.kt)("inlineCode",{parentName:"p"},"systemd")," unit file for the controller-manager:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"- name: kube-controller-manager.service\n    command: start \n    content: |\n      [Unit]\n      Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/...\n      Requires=kube-apiserver.service\n      After=kube-apiserver.service\n      [Service]\n      ExecStartPre=/usr/bin/curl -L -o /opt/bin/kube-controller-manager -z /opt/bin/kube-controller-manager https://storage.googleapis.com...\n      ExecStartPre=/usr/bin/chmod +x /opt/bin/kube-controller-manager\n      ExecStart=/opt/bin/kube-controller-manager \\\n        --service-account-private-key-file=/opt/bin/kube-serviceaccount.key \\\n        --root-ca-file=/var/run/kubernetes/apiserver.crt \\\n        --cp=127.0.0.1:8080 \\\n...\n")),(0,o.kt)("p",null,"Familiarity with the configuration of each components and the options available come with more practice.  Expect the option to change as Kubernetes continues to rapidly develop."),(0,o.kt)("p",null,"An example, the API serve is a highly configurable component. Here's the ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/"},"documentation for configuring")," it."),(0,o.kt)("h3",{id:"using-hyperkube"},"Using Hyperkube"),(0,o.kt)("p",null,"Instead of system deamons, the API server, scheduler, and controller-manager can be run as containers.  This is how ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm")," runs them. Similar to minikube, hyperkube runs as an all in one binary ",(0,o.kt)("a",{parentName:"p",href:"https://console.cloud.google.com/gcr/images/google-containers/GLOBAL/hyperkube"},"which Google hosts")," as a container (this may require adding a new repository so Docker can find and download the image)."),(0,o.kt)("p",null,"Using hyperkube runs a kubelet as a system daemon and then reads manifests for instructions on how to run the other components.  Running hyperkube is also a good way to begin learning the different configuration flags of the components that form the cp.  You can get more information on these flags by downloading the image and running the help commands:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --rm gcr.io/google_containers/hyperkube:v1.16.7 /hyperkube kube-apiserver --help\n\ndocker run --rm gcr.io/google_containers/hyperkube:v1.16.7 /hyperkube kube-scheduler --help\n\ndocker run --rm gcr.io/google_containers/hyperkube:v1.16.7 /hyperkube kube-controller-manager --help\n")),(0,o.kt)("h3",{id:"compiling-from-source"},"Compiling from source"),(0,o.kt)("p",null,"Apart from these useful tool, Kubernetes can also be compiled from source by cloning the repository and building the binaries.  Building can be done natively with Golang or via Docker containers."),(0,o.kt)("p",null,"To build via Golang, first ",(0,o.kt)("a",{parentName:"p",href:"https://go.dev/doc/install"},"install it"),". Then clone the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubernetes/kubernetes"},(0,o.kt)("inlineCode",{parentName:"a"},"kubernetes")," repo")," and run the ",(0,o.kt)("inlineCode",{parentName:"p"},"make")," command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cd $GOPATH\ngit clone https://github.com/kubernetes/kubernetes\ncd kubernetes\nmake\n")),(0,o.kt)("p",null,"For building with Docker, instead of ",(0,o.kt)("inlineCode",{parentName:"p"},"make")," run ",(0,o.kt)("inlineCode",{parentName:"p"},"make quick-release"),"."),(0,o.kt)("p",null,"The built binaries will be in the ",(0,o.kt)("inlineCode",{parentName:"p"},"__output/bin")," directory."),(0,o.kt)("h2",{id:"lab-exercises"},"Lab Exercises"),(0,o.kt)("h3",{id:"lab-31---install-kubernetes"},"Lab 3.1 - Install Kubernetes"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"SSH into master node")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ssh -i <PEM key name> <user>@<IP address>\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"wget")," the course materials.")),(0,o.kt)("div",{className:"admonition admonition-important alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"important")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"Check the ",(0,o.kt)("a",{parentName:"p",href:"https://training.linuxfoundation.org/cm/LFS258/"},"course material page")," before running to make sure you are downloading the latest tarball"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://training.linuxfoundation.org/cm/LFS258/LFS258_V2021-09-20_SOLUTIONS.tar.xz \\\n    --user=LFtraining --password=Penguin2014\n\ntar -xvf LFS258_V2021-09-20_SOLUTIONS.tar.xz\n")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"Become root and update/upgrade the system.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo -i\n\napt-get update && apt-get upgrade -y\n")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"-y")," flag will accept all prompt to make the upgrade go faster so you are not prompted for every package upgrade."),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Install an editor, ",(0,o.kt)("inlineCode",{parentName:"li"},"nano"),", ",(0,o.kt)("inlineCode",{parentName:"li"},"vim"),", and ",(0,o.kt)("inlineCode",{parentName:"li"},"emacs")," all work well.  The labs are designed to use ",(0,o.kt)("inlineCode",{parentName:"li"},"vim"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"apt-get install -y vim\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Install container runtime.  The course suggests Docker, as that is the default runtime when building with ",(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm")," on Ubuntu at the moment.  For an added challenge (maybe try these labs again with this option?) you could use cri-o, but at the moment that takes multiple steps.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"apt-get install -y docker.io\n")),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Add a new repo for Kubernetes. Create the file and add an entry for the main repo for the distro we are using (Ubuntu in my case).  Even though we are using Ubuntu 18.04, we'll use the ",(0,o.kt)("inlineCode",{parentName:"li"},"kubernetes-xenial")," repo. Also include the keyword ",(0,o.kt)("inlineCode",{parentName:"li"},"main"),"  Note there are four sections to the entry.")),(0,o.kt)("p",null,"Creating the file:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim /etc/apt/sources.list.d/kubernetes.list\n")),(0,o.kt)("p",null,"The entry should look like:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"deb http://apt.kubernetes.io/ kubernetes-xenial main\n")),(0,o.kt)("ol",{start:7},(0,o.kt)("li",{parentName:"ol"},"Add a GPG key for the packages")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n")),(0,o.kt)("ol",{start:8},(0,o.kt)("li",{parentName:"ol"},"Update the system again, with the new repo declared to download the latest repo information.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"apt-get update\n")),(0,o.kt)("ol",{start:9},(0,o.kt)("li",{parentName:"ol"},"Install the software.  New versions release regularly but there are often bugs. To use the latest, omit the ",(0,o.kt)("inlineCode",{parentName:"li"},"=<version>")," from the following commands. Because of this we will install the most recent stable versions. In a later lab, the cluster will be upgraded to a newer version.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"apt-get install -y kubeadm=1.21.1-00 kubelet=1.21.1-00 kubectl=1.21.1-00\n\napt-mark hold kubelet kubeadm kubectl\n")),(0,o.kt)("ol",{start:10},(0,o.kt)("li",{parentName:"ol"},"Decide on a pod network.  As discussed previously, this should take into account the anticipated demands on the cluster.  There can only be one pod network per cluster, although there is a project, CNI-genie that is trying to change that.")),(0,o.kt)("p",null,"The network needs to allow container-to-container, pod-to-pod, pod-to-service, and external-to-service communication. Docker uses host-private networking (",(0,o.kt)("inlineCode",{parentName:"p"},"docker0")," virtual bridge and ",(0,o.kt)("inlineCode",{parentName:"p"},"veth")," interfaces) which requires being on the host to communicate."),(0,o.kt)("p",null,"For this we will use Calico as the network plugin to use ",(0,o.kt)("em",{parentName:"p"},"Network Policies")," later in the course. Calico does not deploy using the CNI by default at the moment. Once downloaded, we need to look for the expected IPv4 range the containers will use in the configuration file."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://docs.projectcalico.org/manifests/calico.yaml\n")),(0,o.kt)("ol",{start:11},(0,o.kt)("li",{parentName:"ol"},"With the manifest downloaded, look through it for the IPv4 pool assigned to the containers (the ",(0,o.kt)("inlineCode",{parentName:"li"},"less")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"cat")," commands are good for this).  Also take a moment while paging through to look at some of the other settings. The ",(0,o.kt)("inlineCode",{parentName:"li"},"CALICO_IPV4POOL_CIDR")," must match the pool given to ",(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm init"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat calico.yaml\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"calico ipv4 pool",src:n(5104).Z,width:"1286",height:"194"})),(0,o.kt)("ol",{start:12},(0,o.kt)("li",{parentName:"ol"},"Find the IP address for the primary interface of the cp server.  There are two ways to do this:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"hostname -i\n")),(0,o.kt)("p",null,"or "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ip addr show\n")),(0,o.kt)("ol",{start:13},(0,o.kt)("li",{parentName:"ol"},"Add a local DNS alias for the cp server by editing the /etc/hosts file and adding an entry for the IP we found in the last step with the alias ",(0,o.kt)("inlineCode",{parentName:"li"},"k8scp"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim /etc/hosts\n")),(0,o.kt)("ol",{start:14},(0,o.kt)("li",{parentName:"ol"},"Create a configuration file for the cluster. For Docker, we need to configure the cp endpoint, software version, and podSubnet values.  For cri-o there are many more things needed in the configuration.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim kubeadm-config.yaml\n")),(0,o.kt)("p",null,"In the config file should be this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: kubeadm.k8s.io/v1beta2\nkind: ClusterConfiguration\nkubernetesVersion: 1.21.1           #<-- Use the word stable for newest version\ncontrolPlaneEndpoint: "k8scp:6443"  #<-- Use the node alias not the IP\nnetworking:\n  podSubnet: 192.168.0.0/16         #<-- Match the IP range from the Calico config file\n')),(0,o.kt)("ol",{start:15},(0,o.kt)("li",{parentName:"ol"},"Initialize the cp. This output is likely to change as the software continues to mature. It will also give you a token to use to join worker nodes later, this can be retrieved again using ",(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm token list"),".  You will also be asked to configure a pod network, and the Calico configuration file will be passed for this.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubeadm init --config=kubeadm-config.yaml --upload-certs | tee kubeadm-init.out\n")),(0,o.kt)("p",null,"Once the cp is initialize, there are commands to run not as root. To exit as the root user run"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"exit\n")),(0,o.kt)("p",null,"Then run the following commands:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir -p $HOME/.kube\n\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nless .kube/config\n")),(0,o.kt)("ol",{start:17},(0,o.kt)("li",{parentName:"ol"},"Apply the network plugin")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo cp /root/calico.yaml .\n\nkubectl apply -f calico.yaml\n")),(0,o.kt)("ol",{start:18},(0,o.kt)("li",{parentName:"ol"},"We'll next install the autocompletion to make working with ",(0,o.kt)("inlineCode",{parentName:"li"},"kubectl")," a little easier.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt-get install bash-completion -y\n")),(0,o.kt)("p",null,"Then restart the terminal session and do the following:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'source <(kubectl completion bash)\n\necho "source <(kubectl completion bash)" >> $HOME/.bashrc\n')),(0,o.kt)("ol",{start:19},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Test the autocomplete installation worked using tab as you type to autocomplete the command.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"View the config values that we could have used in the ",(0,o.kt)("inlineCode",{parentName:"p"},"kubeadm-config.yaml"),"."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo kubeadm config print init-defaults\n")),(0,o.kt)("h3",{id:"lab-32---grow-the-cluster"},"Lab 3.2 - Grow the cluster"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"SSH into the worker node and use the same process as the cp node to get all the software installed on the worker node. This is steps 1 and 3-9 in the ",(0,o.kt)("a",{parentName:"p",href:"#lab-31---install-kubernetes"},"previous section"),".")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Find your IP address for the ",(0,o.kt)("strong",{parentName:"p"},"cp node"),".  Reminder that you can do this again with ",(0,o.kt)("inlineCode",{parentName:"p"},"hostname -i"),".")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Next we want to join the cp node and the worker.  Remember that the join command is printed in the console but this command only works for 2 hours until it expires, so in the future we will need to generate our own.  To do this:"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo kubeadm token create\n")),(0,o.kt)("p",null,"And then to list the token run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo kubeadm token list\n")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Create a Discovery Token CA Cert Hash on the ",(0,o.kt)("strong",{parentName:"li"},"cp")," to make sure there is a secure connection between it and the worker node.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"openssl x509 -pubkey \\\n    -in /etc/kubernetes/pki/ca.crt | openssl rsa \\\n    -pubin -outform der 2>/dev/null | openssl dgst \\\n    -sha256 -hex | sed's/\u02c6.* //'\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"On the ",(0,o.kt)("strong",{parentName:"li"},"worker")," node add a hostname alias for the ",(0,o.kt)("strong",{parentName:"li"},"cp")," name like we did originally on the cp node in the previous lab, with the alias ",(0,o.kt)("inlineCode",{parentName:"li"},"k8scp"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim /etc/hosts\n")),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Next we can join the ",(0,o.kt)("strong",{parentName:"li"},"worker"),"/",(0,o.kt)("strong",{parentName:"li"},"second")," node to the ",(0,o.kt)("strong",{parentName:"li"},"cp"),".  We will use the token and the hash (a ",(0,o.kt)("inlineCode",{parentName:"li"},"sha256"),") to join them.  The ",(0,o.kt)("inlineCode",{parentName:"li"},"kube init")," would have an example of this to use if within 2 hours of running the command. Otherwise, we would build the command from the token and hash we just created. We'll also use the hostname alias we setup and port ",(0,o.kt)("inlineCode",{parentName:"li"},"6443"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubeadm join \\\n    --token <token> \\\n    k8scp:6443 \\\n    --discovery-token-ca-cert-hash sha256:<hash>\n")),(0,o.kt)("p",null,"You can check this worked by running "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get nodes\n")),(0,o.kt)("p",null,"on the ",(0,o.kt)("strong",{parentName:"p"},"cp")," node.  "),(0,o.kt)("ol",{start:7},(0,o.kt)("li",{parentName:"ol"},"Now exit root on the ",(0,o.kt)("strong",{parentName:"li"},"worker")," node and try to run kubectl to get the nodes. It should fail because there is no local configuration to access the cluster.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"exit\nkubectl get nodes\nls -l .kube\n")),(0,o.kt)("p",null,"The second like should fail due to the lack of configuration and the 3rd should fail due to the file not existing."),(0,o.kt)("h3",{id:"lab-33---finish-cluster-setup"},"Lab 3.3 - Finish cluster setup"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"View available nodes of the cluster.  On the ",(0,o.kt)("strong",{parentName:"li"},"cp")," node run")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get nodes\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"Look at the details on the ",(0,o.kt)("strong",{parentName:"li"},"cp")," node. Notice that ",(0,o.kt)("inlineCode",{parentName:"li"},"Taints"),". The cp does not run non-infrastructure pods by default for security and resource contention.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl describe node k8scp\n")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"Enable non-infrastructure pods to run. For training we allow usage of the node but this can be skipped when setting up for a production environment.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl describe node | grep -i taint\n\nkubectl taint nodes --all node-role.kubernetes.io/master-\n")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Determine if the DNS and Calico pods are ready for use.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods --all-namespaces\n")),(0,o.kt)("p",null,"If the CoreDNS pods seem to be getting stuck you may need to delete them to force them to be recreated."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system delete coredns-<instance> coredns-<instance>\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Once this finishes, run ")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ip a\n")),(0,o.kt)("p",null,"and you should see a new tunnel interface, ",(0,o.kt)("inlineCode",{parentName:"p"},"tunl0"),", and more new interfaces as other pods are deployed."),(0,o.kt)("h3",{id:"lab-34---deploy-a-simple-application"},"Lab 3.4 - Deploy a simple application"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Create a new ",(0,o.kt)("inlineCode",{parentName:"li"},"deployment"),", which deploys a new container running an application and verify it is running.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create deployment nginx --image=nginx\nkubectl get deployments\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"View the details of the deployment")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl describe deployment nginx\n")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"View the basic steps the cluster made to create the deployment")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get events\n")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Get the description of the deployment in YAML format and notice, about halfway down in the output is the current status of the deployment.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployment nginx -o yaml\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Run the command but pipe the output to a file. Then edit the file and remove ",(0,o.kt)("inlineCode",{parentName:"li"},"creationTimestamp"),",",(0,o.kt)("inlineCode",{parentName:"li"},"resourceVersion"),", and ",(0,o.kt)("inlineCode",{parentName:"li"},"uid")," sections. Also remove everything from ",(0,o.kt)("inlineCode",{parentName:"li"},"status")," down.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployment nginx -o yaml > first.yaml\n\nvim first.yaml\n")),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Delete the existing deployment")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete deployment nginx\n")),(0,o.kt)("ol",{start:7},(0,o.kt)("li",{parentName:"ol"},"Recreate the deployment, this time with our edited YAML file.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f first.yaml\n")),(0,o.kt)("ol",{start:8},(0,o.kt)("li",{parentName:"ol"},"Get the output of this deployment and compare it to the first.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployment nginx -o yaml > second.yaml\n\ndiff first.yaml second.yaml\n")),(0,o.kt)("ol",{start:9},(0,o.kt)("li",{parentName:"ol"},'Now we will learn some ways to get useful YAML and JSON output.  The first is by "creating" a deployment but use the ',(0,o.kt)("inlineCode",{parentName:"li"},"--dry-run")," flag to just see the deployment spec. It should look very similar to the ones modified in previous steps.  Also verify that no deployment was actually created by getting the deployment and verifying only the original ",(0,o.kt)("inlineCode",{parentName:"li"},"nginx")," deployment is there.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create deployment two --image=nginx --dry-run=client -o yaml\nkubectl get deployment\n")),(0,o.kt)("p",null,"We can also get the YAML for an existing deployment as seen in previous steps."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployments nginx -o yaml\n")),(0,o.kt)("p",null,"We can also output to JSON."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployments nginx -o json\n")),(0,o.kt)("ol",{start:10},(0,o.kt)("li",{parentName:"ol"},"Now back to our ",(0,o.kt)("inlineCode",{parentName:"li"},"nginx")," deployment.  To be able to talk to the web server from external points of the cluster we need to create a ",(0,o.kt)("inlineCode",{parentName:"li"},"service"),".  First look at the help page for the ",(0,o.kt)("inlineCode",{parentName:"li"},"expose")," command. Notice some of the examples in the help field.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl expose -h\n")),(0,o.kt)("p",null,"Try to gain access to the server but notice it will fail since a port was not given."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl expose deployment/nginx\n")),(0,o.kt)("ol",{start:11},(0,o.kt)("li",{parentName:"ol"},"Now update the deployment container spec in the YAML file with the port information.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim first.yaml\n")),(0,o.kt)("p",null,"and add the following fields under the ",(0,o.kt)("inlineCode",{parentName:"p"},"spec.template.spec.containers")," section of the file."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"ports:\n- containerPort: 80\n  protocol: TCP\n")),(0,o.kt)("p",null,"There are a few subcommands that will update the configuration. ",(0,o.kt)("inlineCode",{parentName:"p"},"apply"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"edit"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"path")," all do it non-disruptively."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"apply")," does a 3-way diff on the previous, current, and supplied input to determine what changes to make.  Fields that are not mentioned will not be touched."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"edit")," gets the current configuration, opens an editor, and then runs an ",(0,o.kt)("inlineCode",{parentName:"p"},"apply")," on the made changes."),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"patch")," can be used to update API objects in place."),(0,o.kt)("p",null,"For changes that cannot be made once te object is initialized, ",(0,o.kt)("inlineCode",{parentName:"p"},"replace")," can be used which will destroy the object and recreate it.  For the ",(0,o.kt)("inlineCode",{parentName:"p"},"nginx")," deployment we must do this."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl replace -f first.yaml\n")),(0,o.kt)("p",null,"Then check to make sure the deployment and pod status show that they are ready."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deploy,pod\n")),(0,o.kt)("ol",{start:12},(0,o.kt)("li",{parentName:"ol"},"Now try to expose the web server again.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl expose deployment/nginx\n")),(0,o.kt)("p",null,"Then check the service and endpoint information.  Take note of the ",(0,o.kt)("inlineCode",{parentName:"p"},"ClusterIP")," (provided by Calico) in the service information and the ",(0,o.kt)("inlineCode",{parentName:"p"},"Endpoint")," in the endpoint information to use for later."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get svc nginx\n\nkubectl get ep nginx\n")),(0,o.kt)("p",null,"10.96.14.131\n192.168.157.133:80"),(0,o.kt)("ol",{start:13},(0,o.kt)("li",{parentName:"ol"},"Determine which node the container is running on.  Log into that node and run a ",(0,o.kt)("inlineCode",{parentName:"li"},"tcpdump")," (this may need to be installed) to see the traffic on ",(0,o.kt)("inlineCode",{parentName:"li"},"tunl0"),".  While the ",(0,o.kt)("inlineCode",{parentName:"li"},"tcpdump")," is still running use ",(0,o.kt)("inlineCode",{parentName:"li"},"curl")," to send an HTTP request.")),(0,o.kt)("p",null,"On the ",(0,o.kt)("strong",{parentName:"p"},"cp node"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl describe pod nginx-<specific deployment> | grep Node:\n")),(0,o.kt)("p",null,"On the node that is running the pod (in my case thw worker node):"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo tcpdump -i tunl0\n")),(0,o.kt)("p",null,"Now ",(0,o.kt)("inlineCode",{parentName:"p"},"curl")," the ",(0,o.kt)("inlineCode",{parentName:"p"},"ClusterIP")," on port ",(0,o.kt)("inlineCode",{parentName:"p"},"80")," and also try to ",(0,o.kt)("inlineCode",{parentName:"p"},"curl")," the ",(0,o.kt)("inlineCode",{parentName:"p"},"Endpoint"),". You should get the same response."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"curl <ClusterIP>:80\ncurl <Endpoint>\n")),(0,o.kt)("ol",{start:14},(0,o.kt)("li",{parentName:"ol"},"Now scale the deployment to three web servers.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get deployment\n\nkubectl scale deployment nginx --replicas=3\n\nkubectl get deployment nginx\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"scaled deployment",src:n(4971).Z,width:"650",height:"154"})),(0,o.kt)("ol",{start:14},(0,o.kt)("li",{parentName:"ol"},"Now look at the endpoints again. There should now be three.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get ep nginx\n")),(0,o.kt)("p",null,"Now find the oldest deployment running and delete it so that it is recreated."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pod -o wide\nkubectl delete pod nginx-<specific deployment> \n")),(0,o.kt)("p",null,"Then confirm the new pod is running. You should see one that is newer than the other two."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get po\n")),(0,o.kt)("p",null,"If you view the endpoints again you will notice the original IP is no longer in use. Try to ",(0,o.kt)("inlineCode",{parentName:"p"},"curl")," the ",(0,o.kt)("inlineCode",{parentName:"p"},"ClusterIP")," and any of the ",(0,o.kt)("inlineCode",{parentName:"p"},"Endpoints")," again. You should still have access to the cluster.  Access is only available within the cluster though.  Once doe you can stop the ",(0,o.kt)("inlineCode",{parentName:"p"},"tcpdump")," with ",(0,o.kt)("inlineCode",{parentName:"p"},"ctrl-C"),"."),(0,o.kt)("h3",{id:"lab-35---access-from-outside-the-cluster"},"Lab 3.5 - Access from outside the cluster"),(0,o.kt)("p",null,"Access to the cluster from external sources can be configured using Services with a DNS-addon or environment variables.  We'll use environment variables."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Gt this list of pods and then ",(0,o.kt)("inlineCode",{parentName:"li"},"exec")," into on to print the environment variables with ",(0,o.kt)("inlineCode",{parentName:"li"},"printenv"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get po\n\nkubectl exec nginx-<specific deployment> -- printenv | grep KUBERNETES\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"Find the existing service for ",(0,o.kt)("inlineCode",{parentName:"li"},"nginx")," and delete it.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get svc\n\nkubectl delete svc nginx\n")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"Now create the service again, but this time as type ",(0,o.kt)("inlineCode",{parentName:"li"},"LoadBalancer"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl expose deployment nginx --type=LoadBalancer\n\nkubectl get svc\n")),(0,o.kt)("p",null,"Note the ",(0,o.kt)("inlineCode",{parentName:"p"},"EXTERNAL_IP")," will be pending until a provider responds with a load balancer."),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Now on your local machine, in the browser, type the public IP of the node and the port given for the service in the previous step.  You should get the nginx welcome page.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Now scale down the replicas to zero and confirm they are all down."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl scale deployment nginx --replicas=0\n\nkubectl get po\n")),(0,o.kt)("p",null,"Access to the web server should fail now. Scale back up to two replicas and try again, the web server should be working."),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Now delete the deployment to recover the system resources.  Note that the service and endpoints need to also be deleted.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete deployments nginx\n\nkubectl delete ep nginx\n\nkubectl delete svc nginx\n")),(0,o.kt)("h2",{id:"knowledge-check"},"Knowledge check"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"kubeadm")," is used to ",(0,o.kt)("strong",{parentName:"li"},"create a cluster and add nodes")),(0,o.kt)("li",{parentName:"ul"},"The main binary for working with object of a Kubernetes cluster is ",(0,o.kt)("strong",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"strong"},"kubectl"))),(0,o.kt)("li",{parentName:"ul"},"There can be ",(0,o.kt)("strong",{parentName:"li"},"1")," pod network per cluster"),(0,o.kt)("li",{parentName:"ul"},"The ",(0,o.kt)("inlineCode",{parentName:"li"},"~/.kube/config")," file contains ",(0,o.kt)("strong",{parentName:"li"},"endpoints"),", ",(0,o.kt)("strong",{parentName:"li"},"SSL keys"),", and ",(0,o.kt)("strong",{parentName:"li"},"contexts"),".")))}d.isMDXComponent=!0},5104:function(e,t,n){t.Z=n.p+"assets/images/ch03-lab-calico-ip-pool-b8ebdc30af337f6f3c6c4fcdeabd09a1.png"},4971:function(e,t,n){t.Z=n.p+"assets/images/ch03-lab-scale-deployment-63b95ad4e3566a7760c2fe2da51a5bfe.png"}}]);