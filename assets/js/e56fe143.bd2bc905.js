"use strict";(self.webpackChunkcka_prep_2=self.webpackChunkcka_prep_2||[]).push([[2464],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return h}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=c(n),h=o,m=u["".concat(s,".").concat(h)]||u[h]||p[h]||r;return n?a.createElement(m,i(i({ref:t},d),{},{components:n})):a.createElement(m,i({ref:t},d))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},5857:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return c},toc:function(){return d},default:function(){return u}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),i=["components"],l={id:"chapter09",title:"Services"},s=void 0,c={unversionedId:"fundamentals/chapter09",id:"fundamentals/chapter09",title:"Services",description:"Course Reading",source:"@site/docs/fundamentals/chapter09.md",sourceDirName:"fundamentals",slug:"/fundamentals/chapter09",permalink:"/cka-prep/docs/fundamentals/chapter09",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/fundamentals/chapter09.md",tags:[],version:"current",frontMatter:{id:"chapter09",title:"Services"},sidebar:"tutorialSidebar",previous:{title:"Volumes and Data",permalink:"/cka-prep/docs/fundamentals/chapter08"},next:{title:"Helm",permalink:"/cka-prep/docs/fundamentals/chapter10"}},d=[{value:"Course Reading",id:"course-reading",children:[{value:"Learning objectives",id:"learning-objectives",children:[],level:3},{value:"Overview",id:"overview",children:[],level:3},{value:"Service update pattern",id:"service-update-pattern",children:[],level:3},{value:"Accessing an application with a service",id:"accessing-an-application-with-a-service",children:[],level:3},{value:"Types of services",id:"types-of-services",children:[{value:"ClusterIP",id:"clusterip",children:[],level:4},{value:"NodePort",id:"nodeport",children:[],level:4},{value:"LoadBalancer",id:"loadbalancer",children:[],level:4},{value:"ExternalName",id:"externalname",children:[],level:4},{value:"Ingress controllers",id:"ingress-controllers",children:[],level:4}],level:3},{value:"Services diagram",id:"services-diagram",children:[],level:3},{value:"Overall network view",id:"overall-network-view",children:[],level:3},{value:"Local proxy for development",id:"local-proxy-for-development",children:[],level:3},{value:"DNS",id:"dns",children:[],level:3},{value:"Verifying DNS registration",id:"verifying-dns-registration",children:[],level:3}],level:2},{value:"Lab Exercises",id:"lab-exercises",children:[{value:"Lab 9.1 - Deploy a new Service",id:"lab-91---deploy-a-new-service",children:[],level:3},{value:"Lab 9.2 - Configure a NodePort",id:"lab-92---configure-a-nodeport",children:[],level:3},{value:"Lab 9.3 - Working with CoreDNS",id:"lab-93---working-with-coredns",children:[],level:3},{value:"Lab 9.4 - Use labels to manage resources",id:"lab-94---use-labels-to-manage-resources",children:[],level:3}],level:2},{value:"Knowledge check",id:"knowledge-check",children:[],level:2}],p={toc:d};function u(e){var t=e.components,l=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"course-reading"},"Course Reading"),(0,r.kt)("h3",{id:"learning-objectives"},"Learning objectives"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Explain a Kubernetes service"),(0,r.kt)("li",{parentName:"ul"},"Expose an application"),(0,r.kt)("li",{parentName:"ul"},"Discuss the types of services available"),(0,r.kt)("li",{parentName:"ul"},"Start a local proxy"),(0,r.kt)("li",{parentName:"ul"},"Use the cluster DNS")),(0,r.kt)("h3",{id:"overview"},"Overview"),(0,r.kt)("p",null,"Services are the agents connection Pods together or to allow access from outside the cluster. Typically via labels, and refreshed Pods are connected by the service so there is no change in the expected resources at a given Endpoint."),(0,r.kt)("p",null,"There are multiple types of services, each exposed internally or externally. Services also can be used to connect third party external resources, like a database, for example."),(0,r.kt)("p",null,"The kube-proxy operator watched the kube-apiserver for new services and endpoints. Random ports are opened listened on for traffic to the ",(0,r.kt)("inlineCode",{parentName:"p"},"ClusterIP:Port")," and traffic is redirected to the randomly generated endpoint for the service. Services provide automatic load balancing, match label queries. This cannot be configured but there is possibility for session affinity via IP.  A headless service (without a fixed IP or load balancing) can be configured."),(0,r.kt)("p",null,"The unique IP addresses are configured via etcd, so Services implement iptables to route their traffic. Other technologies could be leveraged to provide access to resources later."),(0,r.kt)("h3",{id:"service-update-pattern"},"Service update pattern"),(0,r.kt)("p",null,"Labels on each Pod are used to determine what traffic should be received from a service. Labels can be dynamically updated on an object which can affect which Pods continue to connect to a service."),(0,r.kt)("p",null,"By default, the update pattern is to use a rolling deployment. New Pods are added with a new application version, and because of the automatic load balancing they will receive traffic along with the previous version of the application until the old version Pods are terminated."),(0,r.kt)("p",null,"If there would be an issue where routing traffic to a new and old version of an application during the update would cuase an issue, you may want to take the strategy where you use a more specific label for the new deployment, then turn down the old version, and update the labels to shift traffic to tie back to the original service."),(0,r.kt)("h3",{id:"accessing-an-application-with-a-service"},"Accessing an application with a service"),(0,r.kt)("p",null,"The basic steps for setting up access to a new service is as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl expose deployment/nginx --port=80 --type=NodePort\nkubectl get svc\nkubectl get svc nginx -o yaml\n")),(0,r.kt)("p",null,"You could then hit the nginx server in your browser using the public IP and the port that was exposed with the service (you can find the public IP with a ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pods -o wide")," or a ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get endpoints"),")."),(0,r.kt)("p",null,"Now let's discuss what we actually did to expose the service, step by step. First we used the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl expose")," command to actually create the service.  This service used port 80 and chose a random port to use on the nodes.  You can pass a ",(0,r.kt)("inlineCode",{parentName:"p"},"port")," (which we did) and ",(0,r.kt)("inlineCode",{parentName:"p"},"targetPort"),". We also specified the type of service with the ",(0,r.kt)("inlineCode",{parentName:"p"},"--type=NodePort")," option."),(0,r.kt)("p",null,"Next we ran a ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get svc")," to list all the services and find the one we just created. We see it was created with an internal IP. The range of available cluster IPs and the range of ports that can be used are configurable in the API server startup options."),(0,r.kt)("p",null,"Finally we ran ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get svc nginx -o yaml")," to view the manifest for the service in YAML format."),(0,r.kt)("h3",{id:"types-of-services"},"Types of services"),(0,r.kt)("p",null,"Behind the scenes, a service is an operator in the kube-controller-manager which sends API calls through the kube-apiserver to the network plugin and kube-proxy Pods running on the nodes. The service operator also creates endpoint operators to query the ephemeral IP addresses of Pods with a specific label. These operators work together to manage the firewall rules of the cluster via iptables or ipvs."),(0,r.kt)("h4",{id:"clusterip"},"ClusterIP"),(0,r.kt)("p",null,"This is the default service used. It only provides access internally (except when manually creating an external endpoint). The range of ClusterIPs is defined in API server startup options."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl proxy")," creates a local service to access a ClusterIP, which is helpful in troubleshooting and development scenarios."),(0,r.kt)("h4",{id:"nodeport"},"NodePort"),(0,r.kt)("p",null,"NodePorts are useful for debugging or when static IPs are necessary, like for opening a particular address access through a firewall.  The NodePort range is defined in the cluster configuration."),(0,r.kt)("p",null,"Some of these services build upon each other. A ClusterIP service configures a persistent IP and then directs traffic sent to that address to existing Pods ephemeral addresses, but only within the cluster."),(0,r.kt)("p",null,"When a NodePort service is created, first a ClusterIP is created first. Then a high numbered port is created and a firewall rule is sent out so that traffic to this new port on any node will be sent to the persistent IP, and then the Pods."),(0,r.kt)("h4",{id:"loadbalancer"},"LoadBalancer"),(0,r.kt)("p",null,"The LoadBalancer service was created so requests could be passed through cloud providers.  Private clouds may also implement this service with a cloud provider plugin like CloudStack or OpenStack.  Even without cloud providers, the address is made available for public traffic and packets are spread among Pods in the deployment automatically."),(0,r.kt)("p",null,"LoadBalancers do not create load balancers. Instead, a NodePort is created and makes async requests to use a load balancer. If a listener sees the request, like would occur when using a cloud provider, one would then be created. If no listener sees the request then the status remains ",(0,r.kt)("em",{parentName:"p"},"pending")," since no load balancer responds to the API call."),(0,r.kt)("h4",{id:"externalname"},"ExternalName"),(0,r.kt)("p",null,"ExternalName is a newer service. It has no selectors, nor does it define ports or endpoints. It instead allows for an alias to be returned to an external service.  This redirect happens at the DNS level, not via proxy or forwarding. This type of service is useful for things not yet brought into the Kubernetes cluster. A simple future change will redirect traffic to the internal objects."),(0,r.kt)("h4",{id:"ingress-controllers"},"Ingress controllers"),(0,r.kt)("p",null,"Ingress controllers are not services but instead a microservice running within a Pod. They listen on a high port on whichever node the pod is running on, and then sends traffic to service based on the requested URL. Ingress controllers are not built-in, but they are often used with services to centralize traffic. Ingress controllers will be discussed further later."),(0,r.kt)("h3",{id:"services-diagram"},"Services diagram"),(0,r.kt)("p",null,"Controllers for services and endpoints run in the kube-controller-manager, and send API calls through the kube-apiserver. The kube-apiserver then talks to the network plugin to direct the agents on each node what to do. Each kube-proxy is also sent an API call to manage the firewall locally, which is typically iptables or ipvs. The kube-proxy mode is configured via a flag, ",(0,r.kt)("inlineCode",{parentName:"p"},"mode"),", set on initialization. The mode can be ",(0,r.kt)("inlineCode",{parentName:"p"},"iptables"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"IPVS"),", or ",(0,r.kt)("inlineCode",{parentName:"p"},"userspace"),"."),(0,r.kt)("p",null,"In ",(0,r.kt)("inlineCode",{parentName:"p"},"iptables")," mode, the API continually sends updates to the kube-proxy about changes to Services and Endpoints so rules can be updated as the objects are created, modified, and deleted."),(0,r.kt)("h3",{id:"overall-network-view"},"Overall network view"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"overall network view",src:n(450).Z,width:"561",height:"631"})),(0,r.kt)("h3",{id:"local-proxy-for-development"},"Local proxy for development"),(0,r.kt)("p",null,"When doing local development for an application, a quick way to check the service is to run a local proxy with ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl"),". It captures the shell (unless places in the background). When running, calls can be made to the API via ",(0,r.kt)("inlineCode",{parentName:"p"},"localhost")," and you can also reach the ClusterIP services via the API URLs.  The IP and port to listen on is configurable via command arguments.  To run a proxy:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl proxy\n")),(0,r.kt)("p",null,"This starts a proxy on ",(0,r.kt)("inlineCode",{parentName:"p"},"localhost")," and uses port ",(0,r.kt)("inlineCode",{parentName:"p"},"8001")," by default.  Then to access a service, name ",(0,r.kt)("inlineCode",{parentName:"p"},"example"),", we can use the URL ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost8001/api/v1/namespaces/default/services/example"),". If the service port has a name, you'd append ",(0,r.kt)("inlineCode",{parentName:"p"},":<port name>")," to the end of the URL."),(0,r.kt)("h3",{id:"dns"},"DNS"),(0,r.kt)("p",null,"Since v1.13, CoreDNS has been the default DNS provided. CoreDNS allows for a large amount of flexibility. When a container starts, it runs a server for the zones it is configured to serve, then each server loads one or many plugin chains to provide additional functionality. Like other microservices, clients access it using a service, kube-dns."),(0,r.kt)("p",null,"The in=tree plugins provide most additional common functionality. It is a fairly easy process to write and enable other plugins for extended functionality."),(0,r.kt)("p",null,"Common plugins are used to provide metrics to Prometheus, for error logging, health checking of the application, among other things."),(0,r.kt)("h3",{id:"verifying-dns-registration"},"Verifying DNS registration"),(0,r.kt)("p",null,"To verify DNS setup and check services are being registered, the easiest way is to run a pod with a shell and networking tools, create a service, and then exec in to do DNS lookups."),(0,r.kt)("p",null,"Troubleshooting DNS in the cluster uses typical tools like nslookup, dig, nc, wireshark, etc.  The difference though is we are leveraging a service to access the DNS server, so we need to check labels and selectors in addition to standard network debugging."),(0,r.kt)("p",null,"Other steps, like checking the Network Policies and firewalls can also be done. These will be covered more in a later chapter."),(0,r.kt)("h2",{id:"lab-exercises"},"Lab Exercises"),(0,r.kt)("h3",{id:"lab-91---deploy-a-new-service"},"Lab 9.1 - Deploy a new Service"),(0,r.kt)("p",null,"Services are Kubernetes objects which define policies to access logical sets of Pods. They are typically assigned ",(0,r.kt)("inlineCode",{parentName:"p"},"labels")," so that there is persistent access, even when front or back end containers are terminated and replaced."),(0,r.kt)("p",null,"Native applications can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"Endpoint")," API for access but non-native apps can use a virtual IP-based bridge to access the Pods. These use a ServiceType which could be one of the following:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"ClusterIP - default and only exposes a cluster internal IP, so external access is prevented."),(0,r.kt)("li",{parentName:"ul"},"NodePort - exposes a node IP on a static port. A ClusterIP is created in the background."),(0,r.kt)("li",{parentName:"ul"},"LoadBalancer - exposes the service externally on the cloud provider's load balancer. A ",(0,r.kt)("inlineCode",{parentName:"li"},"NodePort")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"ClusterIP")," are automatically created."),(0,r.kt)("li",{parentName:"ul"},"ExternalName - uses a CNAME record to map the service to the contents of ",(0,r.kt)("inlineCode",{parentName:"li"},"externalRecord"))),(0,r.kt)("p",null,"Services are used to decouple the objects from the traffic so that they can be replaced without any interruption of the client to the backend microservice."),(0,r.kt)("p",null,"To begin this lab we will first create a YAML manifest for a ",(0,r.kt)("inlineCode",{parentName:"p"},"nginx")," deployment with 2 replicas."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"vim nginx-one.yaml\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-one\n  labels:\n    system: secondary\n  namespace: accounting\nspec:\n  selector:\n    matchLabels:\n      system: secondary\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        system: secondary\n    spec:\n      containers:\n      - image: nginx:1.20.1\n        imagePullPolicy: Always\n        name: nginx\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n      nodeSelector:\n        system: secondOne\n")),(0,r.kt)("p",null,"Before we create anything, first let's look at the nodes and their labels."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get nodes --show-labels\n")),(0,r.kt)("p",null,"Now let's get creating our deployment.  Notice we want to create the Deployment in the ",(0,r.kt)("inlineCode",{parentName:"p"},"accounting")," namespace.  First we must create it, otherwise we will get an error. Then we can create the deployment."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create ns accounting\nkubectl create -f nginx-one.yaml\\\nkubectl -n accounting get pods\n")),(0,r.kt)("p",null,"Now that the deployment is created, when you view the pods you should see that the ",(0,r.kt)("inlineCode",{parentName:"p"},"STATUS")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"Pending"),". Now looks the the events when you ",(0,r.kt)("inlineCode",{parentName:"p"},"describe")," one of the pods."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting describe pod nginx-one-<unique ID>\n")),(0,r.kt)("p",null,"You should see a ",(0,r.kt)("inlineCode",{parentName:"p"},"FailedScheduling")," warning due to no node matching the node selector we specified in the manifest."),(0,r.kt)("p",null,"To fix this, let's add the label onto one of the nodes, and then view the labels again."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl label node <worker node name> system=secondOne\nkubectl get nodes --show-labels\n")),(0,r.kt)("p",null,"You should now see a new label, ",(0,r.kt)("inlineCode",{parentName:"p"},"system"),", on the worker node with a value of ",(0,r.kt)("inlineCode",{parentName:"p"},"secondOne"),". Now if you check the Pods again, they should have been scheduled and be ",(0,r.kt)("inlineCode",{parentName:"p"},"Running"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting get pods\nkubectl get pods -l system=secondary --all-namespaces\n")),(0,r.kt)("p",null,"Now that the Pods are up and running, let's expose the the deployment."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting expose deployment nginx-one\nkubectl -n accounting get ep nginx-one\n")),(0,r.kt)("p",null,"You should see some endpoints have been created for the deployment, ending in the port ",(0,r.kt)("inlineCode",{parentName:"p"},"8080")," we specified in the manifest. Try to ",(0,r.kt)("inlineCode",{parentName:"p"},"curl")," one of the endpoints. And then try to curl the endpoint, but instead using port ",(0,r.kt)("inlineCode",{parentName:"p"},"80"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl <endpoint>\ncurl <IP>:80\n")),(0,r.kt)("p",null,"The first command should fail with a connection refusal, while the second ",(0,r.kt)("inlineCode",{parentName:"p"},"curl")," succeeds.  This is because ",(0,r.kt)("inlineCode",{parentName:"p"},"nginx")," listens on port 80 by default. Let's delete the Deployment, change the exposed port to 80, and redeploy."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting delete deployment nginx-one\nvim nginx-one.yaml\nkubectl create -f nginx-one.yaml\n")),(0,r.kt)("h3",{id:"lab-92---configure-a-nodeport"},"Lab 9.2 - Configure a NodePort"),(0,r.kt)("p",null,"Previously we deployed a LoadBalancer. This time we will deploy a NodePort instead using the ",(0,r.kt)("inlineCode",{parentName:"p"},"expose")," command.  NodePorts NAT traffic from outside the cluster. One reason to use a NodePort is to avoid having to use a cloud providers load balancer when deploying one in Kubernetes."),(0,r.kt)("p",null,"Deploy the NodePort and then describe the services."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting expose deployment nginx-one --type=NodePort --name=service-lab\nkubectl -n accounting describe services\n")),(0,r.kt)("p",null,"Find the port number that the NodePort exposed with the ",(0,r.kt)("inlineCode",{parentName:"p"},"service-lab")," service thst was printed out in the ",(0,r.kt)("inlineCode",{parentName:"p"},"describe"),". Then find the cluster hostname or IP address. It should be the first line of this command."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl cluster-info\n")),(0,r.kt)("p",null,"Then you should be able to ",(0,r.kt)("inlineCode",{parentName:"p"},"curl")," the endpoint made up of the hostname/IP and the NodePort port number. Also try in your browser to reach the NodePort by using the public IP of the node you SSH into and the port number."),(0,r.kt)("h3",{id:"lab-93---working-with-coredns"},"Lab 9.3 - Working with CoreDNS"),(0,r.kt)("p",null,"Instead of using IP addresses, we can leverage CoreDNS for predictable hostnames instead. First we will create a Pod for testing using Ubuntu."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"vim nettool.yaml\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: ubuntu\nspec: \n  containers:\n  - name: ubuntu\n    image: ubuntu:latest\n    command: ["sleep"]\n    args: ["infinity"]\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f nettool.yaml\n")),(0,r.kt)("p",null,"Once created, log onto the Pod."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl exec -it ubuntu -- /bin/bash\n")),(0,r.kt)("div",{className:"admonition admonition-important alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"important")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"The following commands should all be run on the ",(0,r.kt)("inlineCode",{parentName:"p"},"ubuntu")," Pod's container. First we will install some tools for investigating the DNS and network."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"apt-get update\napt-get install curl dnsutils -y\n")),(0,r.kt)("p",{parentName:"div"},"Then run the ",(0,r.kt)("inlineCode",{parentName:"p"},"dig")," command. You will see information about root name servers and info about the DNS server responding."),(0,r.kt)("p",{parentName:"div"},"Now take a looks the ",(0,r.kt)("inlineCode",{parentName:"p"},"etc/resolv.conf")," file. This will show us nameservers and the default domain to search if no Fully Qualified Distinguished Name (FQDN) is used. You'll see the first result is ",(0,r.kt)("inlineCode",{parentName:"p"},"default.svc.cluster.local"),". Then use the ",(0,r.kt)("inlineCode",{parentName:"p"},"dig")," command again, this time using the nameserver IP."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cat /etc/resolv.conf\ndig @10.96.0.10 -x 10.96.0.10\n")),(0,r.kt)("p",{parentName:"div"},"Notice the domain name, ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-dns.kube-system.svc.cluster.local.")," and how it uses ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-system.svc.cluster.local.")," instead of ",(0,r.kt)("inlineCode",{parentName:"p"},"default.svc.cluster.local.")," from what we saw in ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/resolv.conf"),", so that it matches the namespace of the service, ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-dns"),"."),(0,r.kt)("p",{parentName:"div"},"Try to ",(0,r.kt)("inlineCode",{parentName:"p"},"curl")," the nginx Pod from the previous section, both using the constructed FQDN, and just the service name."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl service-lab.accounting.svc.cluster.local.\ncurl service-lab\n")),(0,r.kt)("p",{parentName:"div"},"The first should succeed, and the second command should fail, since the ",(0,r.kt)("inlineCode",{parentName:"p"},"ubuntu")," Pod we created is un the ",(0,r.kt)("inlineCode",{parentName:"p"},"default")," namespace, while the ",(0,r.kt)("inlineCode",{parentName:"p"},"nginx")," deployment is in ",(0,r.kt)("inlineCode",{parentName:"p"},"accounting"),"."),(0,r.kt)("p",{parentName:"div"},"Try again, but appending a ",(0,r.kt)("inlineCode",{parentName:"p"},".accounting")," to the end, and the command should succeed, this time. You can then exit the container."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl service-lab.accounting\nexit\n")))),(0,r.kt)("p",null,"Now let's take a look at some of the services in the ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-system")," namespace."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system get svc\nkubectl -n kube-system get svc kube-dns -o yaml\n")),(0,r.kt)("p",null,"Make note of the selectors used in the ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-dns")," service.  Check the Pods which use this label. Then, look at the configuration of one of the CoreDNS Pods."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods -l k8s-app --all-namespaces\nkubectl -n kube-system get pod coredns-<unique ID> -o yaml\n")),(0,r.kt)("p",null,"Notice there is a mounted ConfigMap.  Looks the the ConfigMaps in the ",(0,r.kt)("inlineCode",{parentName:"p"},"kube-system")," namespace and then view the ",(0,r.kt)("inlineCode",{parentName:"p"},"coredns")," ConfigMap."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system get configmaps\nkubectl -n kube-system get configmaps coredns -o yaml\n")),(0,r.kt)("p",null,"You should see the ",(0,r.kt)("inlineCode",{parentName:"p"},"cluster.local")," domain there."),(0,r.kt)("p",null,"Let's make a simple edit to the ConfigMap, so that ",(0,r.kt)("inlineCode",{parentName:"p"},"test.io")," redirects to ",(0,r.kt)("inlineCode",{parentName:"p"},"cluster.local")," by using a rewrite statement."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system edit configmaps coredns\n")),(0,r.kt)("p",null,"Then add ",(0,r.kt)("inlineCode",{parentName:"p"},"rewrite name regex (.*)\\.test\\.io {1}.default.svc.cluster.local")," as the first line under the line starting with ",(0,r.kt)("inlineCode",{parentName:"p"},".:53"),"."),(0,r.kt)("p",null,"Once the ConfigMap is edited, delete the ",(0,r.kt)("inlineCode",{parentName:"p"},"coredns")," Pods so that they recreate looking at the new ConfigMap."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system delete pod coredns-<unique ID 1> coredns-<unique ID 2>\n")),(0,r.kt)("p",null,"Now create a new web server deployment and a ClusterIP associated with it.  Then check the service to get the ClusterIP address and log into the ",(0,r.kt)("inlineCode",{parentName:"p"},"ubuntu")," container from previous steps."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --type=ClusterIP --port=80\nkubectl get svc\nkubectl exec -it ubuntu -- /bin/bash\n")),(0,r.kt)("div",{className:"admonition admonition-important alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"important")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Now, in the shell of the ubuntu container, use ",(0,r.kt)("inlineCode",{parentName:"p"},"dig")," on the ClusterIP of the new ",(0,r.kt)("inlineCode",{parentName:"p"},"nginx")," service that we retrieved in the last step to do the reverse lookup. Use the address you find in the reverse lookup to do a forward lookup"),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"dig -x <nginx ClusterIP>\ndig nginx.default.svc.cluster.local.\n")),(0,r.kt)("p",{parentName:"div"},"Then try the FQDN but using the alias we created using the rewrite command in the ConfigMap."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"dig nginx.test.io\nexit\n")),(0,r.kt)("p",{parentName:"div"},"You should see the answer section uses the original name, not the requested FQDN."))),(0,r.kt)("p",null,"Now, let's edit the rewrite command in the ",(0,r.kt)("inlineCode",{parentName:"p"},"coredns")," ConfigMap to add an answer."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system edit configmaps coredns\n")),(0,r.kt)("p",null,"Change the rewrite line we added before to the following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"rewrite stop {\n    name regex (.*)\\.test\\.io {1}.default.svc.cluster.local\n    answer name (.*)\\.default\\.svc\\.cluster\\.local {1}.test.io\n}\n")),(0,r.kt)("p",null,"Then delete the pods again as we did before and exec into the ",(0,r.kt)("inlineCode",{parentName:"p"},"ubuntu")," Pod again."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n kube-system delete pod coredns-<unique ID 1> coredns-<unique ID 2>\nkubectl exec -it ubuntu -- /bin/bash\n")),(0,r.kt)("div",{className:"admonition admonition-important alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"important")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Once inside the Pod try the dig command again on the FQDN."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"dig nginx.test.io\nexit\n")),(0,r.kt)("p",{parentName:"div"},"This time, in the answer, we see the FQDN we used as an argument to the ",(0,r.kt)("inlineCode",{parentName:"p"},"dig")," command is shown."))),(0,r.kt)("p",null,"Now delete the ",(0,r.kt)("inlineCode",{parentName:"p"},"ubuntu")," Pod."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete -f nettools.yaml\n")),(0,r.kt)("h3",{id:"lab-94---use-labels-to-manage-resources"},"Lab 9.4 - Use labels to manage resources"),(0,r.kt)("p",null,"First, try to delete all pods with the ",(0,r.kt)("inlineCode",{parentName:"p"},"system")," label having a value of ",(0,r.kt)("inlineCode",{parentName:"p"},"secondary"),". Then view the Pods again."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete pods -l system=secondary --all-namespaces\nkubectl -n accounting get pods\n")),(0,r.kt)("p",null,"You should see two new pods running, as the controller responsible for the pods still existed. Get the deployments and show the labels. Then delete the deployment responsible for the pods."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n accounting get deploy --show-labels\nkubectl -n accounting delete deploy -l system=secondary\n")),(0,r.kt)("p",null,"Finally, remove the label we added to the node earlier.  Note the ",(0,r.kt)("inlineCode",{parentName:"p"},"-")," after the label name we want to remove, in this case being ",(0,r.kt)("inlineCode",{parentName:"p"},"system"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl label node <node name> system-\n")),(0,r.kt)("h2",{id:"knowledge-check"},"Knowledge check"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"ClusterIP")),", ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"NodePort")),", ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"LoadBalancer")),", and ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"ExternalName"))," are all types of Kubernetes services."),(0,r.kt)("li",{parentName:"ul"},"The ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"kube-proxy"))," watches the API server for configuration changes and iptable updates"),(0,r.kt)("li",{parentName:"ul"},"A ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"LoadBalancer"))," is the type of service that spreads packets among pods in a deployment automatically"),(0,r.kt)("li",{parentName:"ul"},"You can use ",(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"strong"},"kubectl proxy"))," to start a local proxy, helpful for development and testing")))}u.isMDXComponent=!0},450:function(e,t,n){t.Z=n.p+"assets/images/ch09-overall-network-view-7147d9c6448c79e019ee3a356c4c9f48.png"}}]);