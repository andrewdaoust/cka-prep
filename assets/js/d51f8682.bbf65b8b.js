"use strict";(self.webpackChunkcka_prep_2=self.webpackChunkcka_prep_2||[]).push([[8957],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return d}});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var i=n.createContext({}),c=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(i.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,o=e.originalType,i=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),u=c(a),d=l,h=u["".concat(i,".").concat(d)]||u[d]||m[d]||o;return a?n.createElement(h,s(s({ref:t},p),{},{components:a})):n.createElement(h,s({ref:t},p))}));function d(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var o=a.length,s=new Array(o);s[0]=u;var r={};for(var i in t)hasOwnProperty.call(t,i)&&(r[i]=t[i]);r.originalType=e,r.mdxType="string"==typeof e?e:l,s[1]=r;for(var c=2;c<o;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},4851:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return r},contentTitle:function(){return i},metadata:function(){return c},toc:function(){return p},default:function(){return u}});var n=a(7462),l=a(3366),o=(a(7294),a(3905)),s=["components"],r={id:"chapter08",title:"Volumes and Data"},i=void 0,c={unversionedId:"fundamentals/chapter08",id:"fundamentals/chapter08",title:"Volumes and Data",description:"Course Reading",source:"@site/docs/fundamentals/chapter08.md",sourceDirName:"fundamentals",slug:"/fundamentals/chapter08",permalink:"/cka-prep/docs/fundamentals/chapter08",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/fundamentals/chapter08.md",tags:[],version:"current",frontMatter:{id:"chapter08",title:"Volumes and Data"},sidebar:"tutorialSidebar",previous:{title:"Managing State with Deployments",permalink:"/cka-prep/docs/fundamentals/chapter07"},next:{title:"Services",permalink:"/cka-prep/docs/fundamentals/chapter09"}},p=[{value:"Course Reading",id:"course-reading",children:[{value:"Learning objectives",id:"learning-objectives",children:[],level:3},{value:"Overview",id:"overview",children:[],level:3},{value:"Introducing volumes",id:"introducing-volumes",children:[],level:3},{value:"Volume spec",id:"volume-spec",children:[],level:3},{value:"Volume types",id:"volume-types",children:[],level:3},{value:"Shared volume example",id:"shared-volume-example",children:[],level:3},{value:"Persistent volumes and claims",id:"persistent-volumes-and-claims",children:[{value:"Phases of persistent storage",id:"phases-of-persistent-storage",children:[],level:4}],level:3},{value:"Persistent Volume",id:"persistent-volume",children:[],level:3},{value:"Persistent Volume Claim",id:"persistent-volume-claim",children:[],level:3},{value:"Dynamic provisioning",id:"dynamic-provisioning",children:[],level:3},{value:"Using Rook for storage orchestration",id:"using-rook-for-storage-orchestration",children:[],level:3},{value:"Secrets",id:"secrets",children:[],level:3},{value:"Using secrets via environment variables",id:"using-secrets-via-environment-variables",children:[],level:3},{value:"Mounting secrets as volumes",id:"mounting-secrets-as-volumes",children:[],level:3},{value:"Portable data with ConfigMaps",id:"portable-data-with-configmaps",children:[],level:3},{value:"Using ConfigMaps",id:"using-configmaps",children:[],level:3}],level:2},{value:"Lab Exercises",id:"lab-exercises",children:[{value:"Lab 8.1 - Create a ConfigMap",id:"lab-81---create-a-configmap",children:[],level:3},{value:"Lab 8.2 - Create a persistent NFS volume (PV)",id:"lab-82---create-a-persistent-nfs-volume-pv",children:[],level:3},{value:"Lab 8.3 - Creating a persistent volume claim (PVC)",id:"lab-83---creating-a-persistent-volume-claim-pvc",children:[],level:3},{value:"Lab 8.4 - Use a ResourceQuota to limit PVC count and usage",id:"lab-84---use-a-resourcequota-to-limit-pvc-count-and-usage",children:[],level:3}],level:2},{value:"Knowledge check",id:"knowledge-check",children:[],level:2}],m={toc:p};function u(e){var t=e.components,r=(0,l.Z)(e,s);return(0,o.kt)("wrapper",(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"course-reading"},"Course Reading"),(0,o.kt)("h3",{id:"learning-objectives"},"Learning objectives"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Understand and create persistent volumes"),(0,o.kt)("li",{parentName:"ul"},"Configure persistent volume claims"),(0,o.kt)("li",{parentName:"ul"},"Manage volume access modes"),(0,o.kt)("li",{parentName:"ul"},"Deploy applications with persistent data storage"),(0,o.kt)("li",{parentName:"ul"},"Discuss dynamic provisioning of storage"),(0,o.kt)("li",{parentName:"ul"},"Configure secrets and ConfigMaps")),(0,o.kt)("h3",{id:"overview"},"Overview"),(0,o.kt)("p",null,"Traditionally container engines do not offer storage that outlasts the container, since the container is seen as transient.  This could potentially lead to data loss or the need for complex data storage schemes."),(0,o.kt)("p",null,"In Kubernetes, ",(0,o.kt)("strong",{parentName:"p"},"volumes")," share the lifetime of a Pod, not the containers in them.  If a container terminates, the next one still has the data. Volumes are directories, sometimes pre-populated, that is made available to the containers in a Pod.  Volume creation, backend storage, and the data/contents is dependent on the type of volume, of which there are many, which you can ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/storage/volumes/#volume-types"},"read about here"),", each with different configuration and dependencies."),(0,o.kt)("p",null,'There is an effort to adopt the Container Storage Interface (CSI) to reach an industry standard interface for container orchestration to allow access to arbitrary storage systems. Currently, all volume plug-ins are "in-tree", meaning they are built with the Kubernetes source code. A swap to an "out-of-tree" model means 3rd-parties just need to develop their own driver to allow their plugin to be containerized, replacing the Flex plugin which has major security concerns.'),(0,o.kt)("p",null,"Sometimes you may also want the storage to have a lifetime that exceeds a Pod as well, and for this ",(0,o.kt)("strong",{parentName:"p"},"persistent volumes")," are used.  These allow volumes to out live Pods, and then be claimed by Pods with a Persistent Volume Claim. If one Pod is terminated, another one can come along and claim the persistent volume."),(0,o.kt)("p",null,"Two API object previously seen to pass data to Pods are ConfigMaps (for non-encoded data) and Secrets (for encoded data). These two object let you easily pass things like SSH keys, passwords, or configuration to the Pods, just to name a few use cases."),(0,o.kt)("h3",{id:"introducing-volumes"},"Introducing volumes"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"object relationship",src:a(2529).Z,width:"2550",height:"3300"})),(0,o.kt)("p",null,"Volumes can be defined in podSpec and where they are made available.  Each volume configuration requires a name, type, and mount point.One volume can be made available to multiple containers within the Pod, and this can be used as method of communication between containers.  Volumes can also be made available to multiple Pods, and each Pod has access to write to the volume.  Volumes have no concurrency checking, so the potential for corruption when enabling a volume for access from multiple Pods is high unless there is an outside mechanism to lock changes when others are in progress."),(0,o.kt)("p",null,"An access mode is part of the Pod request. As a request, more access may be granted, but not less, and an exact match is attempted to be made.  The cluster groups all the volumes from the requested mode and sorts from smallest to largest.  The claim is then checked against the list for the mode until one of sufficient size is found.  There are three access modes.:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"ReadWriteOnce")," allows read-write by a single node"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"ReadOnlyMany")," allows read only access by multiple nodes"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"ReadWriteMany")," allows read-write access by multiple nodes")),(0,o.kt)("p",null,"Two Pods on the same node can write to a volume that has a ReadWriteOnce access mode, but a Pod on another node would not become ready if trying to attach to that volume due to a ",(0,o.kt)("inlineCode",{parentName:"p"},"FailedAttachVolume")," error."),(0,o.kt)("p",null,"When a volume is requested, the local kubelet run the ",(0,o.kt)("inlineCode",{parentName:"p"},"kubelet_pods.go")," script to get a map of all the devices, determine and create mount points for containers, and then create the symlink on the host node file system to associate the storage to the container.  The API server requests the storage from the ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass")," plugin."),(0,o.kt)("p",null,"If a request for a StorageClass was not made, only the parameters for access mode and size will be used. The volume could come from any of the storage options available, there is no configuration to determine which of the available will be used."),(0,o.kt)("h3",{id:"volume-spec"},"Volume spec"),(0,o.kt)("p",null,"On of many types of storage options in Kubernetes is the ",(0,o.kt)("inlineCode",{parentName:"p"},"emptyDir"),". The kubelet creates a directory in the container, but does not mount any storage.  Any data is written to the shared container space, and as a result is not persistent. When a Pod is destroyed, the data is deleted with the container."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pd\nspec:\n  containers:\n  - image: k8s.gcr.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /cache\n      name: cache-volume\n  volumes:\n  - name: cache-volume\n    emptyDir: {}\n")),(0,o.kt)("p",null,"The YAML above creates a single container Pod with a volume, named ",(0,o.kt)("inlineCode",{parentName:"p"},"cache-volume"),", which would be created in the ",(0,o.kt)("inlineCode",{parentName:"p"},"/cache")," directory in the container."),(0,o.kt)("h3",{id:"volume-types"},"Volume types"),(0,o.kt)("p",null,"There are quite a few different volume type that can be used, some using local storage, others using networked resources."),(0,o.kt)("p",null,"For GCE, AWS, and Azure, there were the ",(0,o.kt)("inlineCode",{parentName:"p"},"gcePersistentDisk"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"awsElasticBlockStore"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"azureDisk")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"azureFile"),", all of these not being depreciated, replaced with new out-of-tree plugins being in alpha or beta that use the new CSI features."),(0,o.kt)("p",null,"There are ",(0,o.kt)("inlineCode",{parentName:"p"},"emptyDir")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"hostPath")," volumes which are easy to use. The ",(0,o.kt)("inlineCode",{parentName:"p"},"emptyDir")," was already discussed. The ",(0,o.kt)("inlineCode",{parentName:"p"},"hostPath")," volume type mounts a resource from the host node filesystem. The resource could be a directory, file socket, character, or block device.  The resource must already exist on the host to be used, and there are two types, ",(0,o.kt)("inlineCode",{parentName:"p"},"DirectoryOrCreate")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"FileOrCreate"),", which create the resource on the host and then use them if they do not exist already."),(0,o.kt)("p",null,"For scenarios with multiple readers a network file system (",(0,o.kt)("inlineCode",{parentName:"p"},"nfs"),") or a Internet Small Computer System Interface (",(0,o.kt)("inlineCode",{parentName:"p"},"iscsi"),") are easy choices."),(0,o.kt)("p",null,"For multiple writers good choices are ",(0,o.kt)("inlineCode",{parentName:"p"},"rdb")," for a block storage option, or ",(0,o.kt)("inlineCode",{parentName:"p"},"cephfs")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"glusterfs")," if either are configured on the cluster."),(0,o.kt)("p",null,"All available volume types can be read about on the official ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/storage/volumes/"},"Kubernetes docs page"),"."),(0,o.kt)("p",null,"The CSI allows for more flexibility and decoupling plugins from the Kubernetes source code. It exists so that arbitrary plugins can be exposed more easily in the future."),(0,o.kt)("h3",{id:"shared-volume-example"},"Shared volume example"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"...\n  containers:\n  - name: alphacont\n    image: busybox\n    volumeMounts:\n    - mountPath: /alphadir\n      name: sharevol\n  - name: betacont\n    image: busybox\n    volumeMounts:\n    - mountPath: /betadir\n      name: sharevol\n  volumes:\n  - name: sharevol\n    emptyDir: {} \n")),(0,o.kt)("p",null,"The snipping from the YAML above would produce a Pod named ",(0,o.kt)("inlineCode",{parentName:"p"},"exampleA")," that has two containers both with access to a volume, ",(0,o.kt)("inlineCode",{parentName:"p"},"sharevol"),". An ",(0,o.kt)("inlineCode",{parentName:"p"},"emptyDir")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"hostPath")," could both easily be used here since both require no additional setup."),(0,o.kt)("p",null,"If the Pod was created and then the following commands are run"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl exec -it exampleA -c betacont -- touch /betadir/foobar\nkubectl exec -it exampleA -c alphacont -- ls -l /alphadir\n")),(0,o.kt)("p",null,"you should see a ",(0,o.kt)("inlineCode",{parentName:"p"},"foobar")," file in the ",(0,o.kt)("inlineCode",{parentName:"p"},"alphadir")," even though the other container wrote the data.  The containers have immediate access to any data the either of them write to the shared volume, and there is nothing stopping them from overwriting each others data. Locking or versioning of the data written by the containers must be considered and implemented into the containerized application to avoid issues with corrupted data."),(0,o.kt)("h3",{id:"persistent-volumes-and-claims"},"Persistent volumes and claims"),(0,o.kt)("p",null,"A persistent volume (pv) is another storage abstraction used to give data a lifetime that exceeds that of a Pod. Pods define a volume that used the type ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolumeClaim")," (",(0,o.kt)("inlineCode",{parentName:"p"},"pvc"),"). The pvc has various parameters to define the size and the type of backend storage, known as the ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass"),".  The cluster then attached the ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolume"),".  The cluster will dynamically use volumes that are available, irrespective of the storage type, allowing the claims to use ay backend storage."),(0,o.kt)("h4",{id:"phases-of-persistent-storage"},"Phases of persistent storage"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Provisioning")," of the persistent volumes can take a few forms. For example, they could be defined ahead of time by the administrator of the cluster, or they might dynamically be created, say by a request from a cloud provider."),(0,o.kt)("p",null,"A ",(0,o.kt)("strong",{parentName:"p"},"binding")," operation occurs when a watch loop see a new PVC, which contains the storage size, access request, and optionally, a ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass"),".  The controller locates a PV that matches this request, or it may have to wait for the ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass")," provisioner to create a new one.  The PV must meet the requested storage size, but it could contain more if only larger PV are available."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Use")," of the PV begins when the volume is mounted to a Pod and continues through the lifetime of that Pod."),(0,o.kt)("p",null,"When the Pod is done with the volume and an API request is sent, the PVC is deleted and the volume is said to be ",(0,o.kt)("strong",{parentName:"p"},"released"),".  The volume remains in the same state from when the claim was deleted until it available to a new claim.  The data on the volume is retained depending on the defined ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolumeReclaimPolicy"),"."),(0,o.kt)("p",null,"Volumes are ",(0,o.kt)("strong",{parentName:"p"},"reclaimed")," when one of three options happen:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"A ",(0,o.kt)("strong",{parentName:"li"},"retain"),", which keeps the data and allows the admin to handle the storage and data."),(0,o.kt)("li",{parentName:"ul"},"A ",(0,o.kt)("strong",{parentName:"li"},"delete"),", removing the API object and the associated storage."),(0,o.kt)("li",{parentName:"ul"},"A ",(0,o.kt)("strong",{parentName:"li"},"recycle"),", which runs a ",(0,o.kt)("inlineCode",{parentName:"li"},"rm -rf /mountpoint")," and then makes the volume available to a new claim.  With dynamic provisioning reaching good stability, this is intended to be depreciated.")),(0,o.kt)("p",null,"Like with other API object, PVs and PVCs can be viewed and described with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pv\nkubectl get pvc\n")),(0,o.kt)("h3",{id:"persistent-volume"},"Persistent Volume"),(0,o.kt)("p",null,"Here is a basic example of a PV declaration that uses a ",(0,o.kt)("inlineCode",{parentName:"p"},"hostPath")," as the storage type."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: PersistentVolume\napiVersion: v1\nmetadata:\n  name: 10Gpv01\n  labels: \n    type: local \nspec:\n  capacity: \n    storage: 10Gi\n  accessModes:\n  - ReadWriteOnce\n  hostPath:\n    path: "/somepath/data01"\n')),(0,o.kt)("p",null,"Each storage type has its own configuration settings.  An example would be a Ceph or GE Persistent Disk that already exists, so it would not need to be configured and would just need to be claimed from the provider."),(0,o.kt)("p",null,"PVs are not namespaced objects, but PVCs are. Stable as of v1.18, Raw Block Volumes are allowed to be statically provisioned, supporting a handful of different volume plugins, which you can find ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#raw-block-volume-support"},"an up-to-date list of here"),"."),(0,o.kt)("p",null,"Locally attached storage is also a stable feature, often used as a part of distributed file systems or for databases."),(0,o.kt)("h3",{id:"persistent-volume-claim"},"Persistent Volume Claim"),(0,o.kt)("p",null,"Once a PV has been created in the cluster, a manifest for a claim can be written and the claim used by a Pod definition.  In the Pod, the volume is a ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolumeClaim"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={Persistent Volume Claim manifest}",title:"{Persistent",Volume:!0,Claim:!0,"manifest}":!0},"kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: myclaim\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 8GI\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={Pod manifest using PVC}",title:"{Pod",manifest:!0,using:!0,"PVC}":!0},"...\n  spec:\n    containers:\n    ...\n    volumes:\n    - name: test-volume\n      persistentVolumeClaim:\n        claimName: myclaim\n")),(0,o.kt)("p",null,"That example is rather simple. A more complex configuration might look like"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={Complex PVC usage}",title:"{Complex",PVC:!0,"usage}":!0},"...\n  volumeMounts:\n  - name: Cephpd\n    mountPath: /data/rbd\n  volumes:\n  - name: rbdpd\n    rbd:\n      monitors:\n      - '10.19.14.22:6789'\n      - '10.19.14.23:6789'\n      - '10.19.14.24:6789'\n      pool: k8s\n      image: client\n      fsType: ext4\n      readOnly: true\n      user: admin\n      keyring: /etc/ceph/keyring\n      imageformat: \"2\"\n      imagefeatures: \"layering\"\n")),(0,o.kt)("h3",{id:"dynamic-provisioning"},"Dynamic provisioning"),(0,o.kt)("p",null,"Using persistent volumes and abstracting that storage with a claim were very powerful, but it originally required an administrator to create them.  Starting in Kubernetes v1.4, dynamic provisioning was added so that a cluster could request storage from an external, pre-configured source.  "),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass")," API resources lets admins define a persistent volume provisioner. This is of a certain type with storage specific configuration.  Once created, users can request a claim from the ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass"),", and the API fills this via auto-provisioning. The resource will be reclaimed as configured by the provider.  Common choices from dynamic storage are AWS and GCE, and there are other options like a Ceph cluster or iSCSI."),(0,o.kt)("p",null,"This is an example of an AWS ",(0,o.kt)("inlineCode",{parentName:"p"},"StorageClass")," using gp2 storage:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: gp2\n  annotations:\n    storageclass.kubernetes.io/is-default-class: "true"\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp2\n  fsType: ext4\n')),(0,o.kt)("h3",{id:"using-rook-for-storage-orchestration"},"Using Rook for storage orchestration"),(0,o.kt)("p",null,"Rook is a project that allows for orchestration of storage by multiple providers. As with other agents within Kubernetes, Rook uses custom resource definitions (CRD) and a custom operator to handle the provisioning of storage according to backend storage type.  Currently several storage providers are supported, such as Ceph, Cassandra, and Network File System (NFS)."),(0,o.kt)("p",null,"You can learn more about the project ",(0,o.kt)("a",{parentName:"p",href:"https://rook.io/"},"here"),"."),(0,o.kt)("h3",{id:"secrets"},"Secrets"),(0,o.kt)("p",null,"For data you don't want readable to the naked eye, like a password, you can use secrets. Secret API resources can take this data and encode or encrypt it so it is not easily readable."),(0,o.kt)("p",null,"You can create, get, and delete secrets like so:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create secret generic --help\nkubectl create secret generic mysql --from-literal=password=root\nkubectl get secrets\nkubectl delete secret mysql\n")),(0,o.kt)("p",null,"Secrets are not encrypted by default, but instead are base64 encoded. To encrypt secrets you must create an ",(0,o.kt)("inlineCode",{parentName:"p"},"EncryptionConfiguration")," with a key and proper identity.  Then the kube-apiserver needs to have the ",(0,o.kt)("inlineCode",{parentName:"p"},"--encryption-provider-flag")," enabled to a previously configured provider (e.g. ",(0,o.kt)("inlineCode",{parentName:"p"},"aescbc")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"ksm"),"). Once enabled, every secret must be recreated since the encryption happens on the write."),(0,o.kt)("p",null,"You can have multiple keys, each is tried during decryption.  The first key of the first provider is used to encrypt secrets. To rotate them, create a new key, restart all kube-apiserver processes, and then recreate all secrets."),(0,o.kt)("p",null,"The encoded string in the secret can be viewed with ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl"),".  The secret is decoded and saved as a string to file, which can be used as an environment variable or in a new directory, similar to how a volume is mounted."),(0,o.kt)("p",null,"Secrets can be made manually with a manifest as well by pasting the encoded string into the manifest.  Here is an example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"echo LFTr@1n | base64\nvim secret.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={secret.yaml}",title:"{secret.yaml}"},"apiVersion: v1\nkind: Secret\nmetadata:\n  name: lf-secret\ndata:\n  password: TEZUckAxbgo=\n")),(0,o.kt)("p",null,"where the output of the ",(0,o.kt)("inlineCode",{parentName:"p"},"echo")," command is entered as the ",(0,o.kt)("inlineCode",{parentName:"p"},"password")," value."),(0,o.kt)("h3",{id:"using-secrets-via-environment-variables"},"Using secrets via environment variables"),(0,o.kt)("p",null,"You can configure a secret as an environment variable for a Pod in a manifest like so:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"...\n  spec:\n    containers:\n    - image: mysql:5.5\n      name: dbpod\n      env:\n      - name: MYSQL_ROOT_PASSWORD\n        valueFrom:\n          secretKeyRef:\n            name: mysql\n            key: password\n")),(0,o.kt)("p",null,"There is not a limit to the number of secrets used, but a secret can only be up to 1 MB in size.  Secrets, just like any other API object, takes up memory, so with large numbers you can deplete memory on a node."),(0,o.kt)("p",null,"Secrets are stored in ",(0,o.kt)("inlineCode",{parentName:"p"},"tmpfs")," storage on the host node, and only get sent to the host Pod.  All volumes that a Pod request must exist before containers are started, secrets are no different."),(0,o.kt)("h3",{id:"mounting-secrets-as-volumes"},"Mounting secrets as volumes"),(0,o.kt)("p",null,"Secrets can also be mounted as files using volume definitions.  The mount path contains a file with the name of the secret."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'...\n  spec:\n    containers:\n    - image: busybox\n      command:\n        - sleep\n        - "3600"\n      volumeMounts:\n      - mountPath: /mysqlpassword\n        name: mysql\n      name: busy\n    volumes:\n    - name: mysql\n        secret:\n          secretName: mysql\n')),(0,o.kt)("p",null,"Once the Pod is up and running, you can verify a secret is accessible with"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl exec -it busybox -- cat /mysqlpassword/password\n")),(0,o.kt)("h3",{id:"portable-data-with-configmaps"},"Portable data with ConfigMaps"),(0,o.kt)("p",null,"ConfigMaps are similar to secrets, but the data they contain is not encoded.  ConfigMaps decouple a container image from their configuration artifacts (and this fits well with Kubernetes model of decoupling). Data is stored as key-value pairs or plain configuration files of any format, and it can come from a collection of files or all files in a directory. ConfigMaps can also be populated from a literal value."),(0,o.kt)("p",null,"Here's an example of how you might use a ConfigMap.  Assume you have a YAML (or any other file type) configuration file on your local machine. You can create a ",(0,o.kt)("inlineCode",{parentName:"p"},"configmap")," object that contains this data. The ",(0,o.kt)("inlineCode",{parentName:"p"},"data")," section of the ConfigMap will contain the configuration when you view the object."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get configmap envyaml -o yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: envyaml\ndata:\n  env.yaml: |\n    ...\n")),(0,o.kt)("p",null,"ConfigMaps are consumed in multiple ways:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Pod environment variables from one or many ConfigMaps"),(0,o.kt)("li",{parentName:"ul"},"For Pod commands"),(0,o.kt)("li",{parentName:"ul"},"Populate a volume, or add ConfigMap data to specific path within a volume"),(0,o.kt)("li",{parentName:"ul"},"Set file names and access modes in a volume"),(0,o.kt)("li",{parentName:"ul"},"Use by system components or controllers")),(0,o.kt)("h3",{id:"using-configmaps"},"Using ConfigMaps"),(0,o.kt)("p",null,"Like secrets, Configmaps must exist prior to use (unless they are marked as optional) and are namespace dependent."),(0,o.kt)("p",null,"Let's first look at the use case of setting an environment variable. The manifest defining the Pods will use a ",(0,o.kt)("inlineCode",{parentName:"p"},"valueFrom")," key and a ",(0,o.kt)("inlineCode",{parentName:"p"},"configMapKeyRef")," value to get the data from the ConfigMap."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: envar-demo\nspec:\n  containers:\n  - name: envar-demo-container\n    env:\n    - name: ENVIRON_VAR_VALUE\n      valueFrom:\n        configMapKeyRef:\n          name: some-config\n          value: someconfig.how\n")),(0,o.kt)("p",null,"Now let's look at creating a volume with a ConfigMap."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmap-volunes\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: some-config\n")),(0,o.kt)("h2",{id:"lab-exercises"},"Lab Exercises"),(0,o.kt)("h3",{id:"lab-81---create-a-configmap"},"Lab 8.1 - Create a ConfigMap"),(0,o.kt)("p",null,"ConfigMaps can ingest data in 3 ways, from a literal value, from files, or from directories.  Let's start by creating some data to ingest into a ConfigMap via file and directory."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'mkdir primary\necho c > primary/cyan\necho m > primary/magenta\necho y > primary/yellow\necho k > primary/black\necho "known as key" >> primary/black\necho blue > favorite\n')),(0,o.kt)("p",null,"And now let's create a ConfigMap with this data using all three types of data ingestion."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create configmap colors \\\n    --from-literal=text=black \\  # Using a literal value\n    --from-file=./favorite \\     # Using a file\n    --from-file=./primary/       # Using a directory\n")),(0,o.kt)("p",null,"Now let's view the ConfigMap in the cluster."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get configmap colors\nkubectl get configmap color -o yaml\n")),(0,o.kt)("p",null,"With a ConfigMap successfully created, we can now use it in a Pod."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim simpleshell.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={simpleshell.yaml}",title:"{simpleshell.yaml}"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: shell-demo\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    env:\n    - name: ilike\n      valueFrom:\n        configMapKeyRef:\n          name: colors\n          key: favorite\n")),(0,o.kt)("p",null,"In this case we are using the ConfigMap to define an environment variable, ",(0,o.kt)("inlineCode",{parentName:"p"},"ilike"),".  Now let's create the Pod and check the variable's value, the we can delete it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f simpleshell.yaml\nkubectl exec shell-demo -- /bin/bash -c 'echo $ilike'\nkubectl delete pod shell-demo\n")),(0,o.kt)("p",null,"All variables in a ConfigMap can be included as environment variables.  We cna replace the ",(0,o.kt)("inlineCode",{parentName:"p"},"env")," section in our YAML manifest with an ",(0,o.kt)("inlineCode",{parentName:"p"},"envFrom"),". Open the ",(0,o.kt)("inlineCode",{parentName:"p"},"simpleshell.yaml")," in vim and change it to this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={simpleshell.yaml}",title:"{simpleshell.yaml}"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: shell-demo\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n  #  env:\n  #  - name: ilike\n  #    valueFrom:\n  #      configMapKeyRef:\n  #        name: colors\n  #        key: favorite\n    envFrom:\n    - configMapRef:\n        name: colors\n")),(0,o.kt)("p",null,"Then create the Pod and check the environment variables. You should see ",(0,o.kt)("inlineCode",{parentName:"p"},"black"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"cyan"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"yellow"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"text"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"favorite"),", and ",(0,o.kt)("inlineCode",{parentName:"p"},"magenta")," environment variables. Then you can delete the Pod again."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f simpleshell.yaml\nkubectl exec shell-demo -- /bin/bash -c 'env'\nkubectl delete pod shell-demo\n")),(0,o.kt)("p",null,"ConfigMaps can also be defined in YAML. Let's create a new one using that method."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim car-map.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={car-map.yaml}",title:"{car-map.yaml}"},"apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fast-car\n  namespace: default\ndata:\n  car.make: Ford\n  car.model: Mustang\n  car.trim: Shelby\n")),(0,o.kt)("p",null,"Then we can create the ConfigMap and view it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f car-map.yaml\nkubectl get configmap fast-car -o yaml\n")),(0,o.kt)("p",null,"We'll use this ConfigMap to mount it as as volume to a Pod.  We'll reuse out ",(0,o.kt)("inlineCode",{parentName:"p"},"simpleshell.yaml"),", open it and ",(0,o.kt)("inlineCode",{parentName:"p"},"vim")," and edit it to match the new spec by removing the ",(0,o.kt)("inlineCode",{parentName:"p"},"env")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"envFrom")," fields and adding in new ",(0,o.kt)("inlineCode",{parentName:"p"},"volumeMounts")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"volumes")," configuration."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={simpleshell.yaml}",title:"{simpleshell.yaml}"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: shell-demo\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: car-vol\n      mountPath: /etc/cars\n  volumes:\n  - name: car-vol\n    configMap:\n      name: fast-car\n")),(0,o.kt)("p",null,"Now let's create the Pod again and then inspect the mounted volume."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f simpleshell.yaml\nkubectl exec shell-demo -- /bin/bash -c 'df -ha |grep car'\nkubectl exec shell-demo -- /bin/bash -c 'cat etc/cars/car.trim'\n")),(0,o.kt)("p",null,"We can then delete the Pod and the ConfigMaps."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete pod shell-demo\nkubectl delete configmap fast-car colors\n")),(0,o.kt)("h3",{id:"lab-82---create-a-persistent-nfs-volume-pv"},"Lab 8.2 - Create a persistent NFS volume (PV)"),(0,o.kt)("p",null,"To set up an NFS PV we first need an NFS server."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt-get update && sudo apt-get install -y nfs-kernel-server\n")),(0,o.kt)("p",null,"Then we will make and populate a directory to be shared."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo mkdir /opt/sfw\nsudo chmod 1777 /opt/sfw\nsudo bash -c 'echo software > /opt/sfw/hello.txt'\n")),(0,o.kt)("p",null,"Now we will edit the NFS file server to share the new directory we created.  We will begin by sharing the directory to all but we can adjust this later if needed by using ",(0,o.kt)("inlineCode",{parentName:"p"},"snoop")," to see the inbound request and then update to a more narrow scope."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo vim /etc/exports\n")),(0,o.kt)("p",null,"When ",(0,o.kt)("inlineCode",{parentName:"p"},"vim")," opens, add the following line:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"/opt/sfw/ *(rw,sync,no_root_squash,subtree_check)\n")),(0,o.kt)("p",null,"And then force the file to be re-read."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo exportfs -ra\n")),(0,o.kt)("div",{className:"admonition admonition-important alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"Worker Node")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"Now let's switch to the worker node and test the NFS by mounting and inspecting it."),(0,o.kt)("pre",{parentName:"div"},(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt-get -y install nfs-common\nshowmount -e k8scp\nsudo mount k8scp:/opt/sfw /mnt\nls -l /mnt\n")),(0,o.kt)("p",{parentName:"div"},"You should see the ",(0,o.kt)("inlineCode",{parentName:"p"},"hello.txt")," file we created on the cp node."))),(0,o.kt)("p",null,"Now back on the cp node, let's create a YAML file to define the persistent volume. When defining a persistent volume in YAML, only syntax is checked, so any misspelling in a directory name will not cause an error, but the Pod will not start.  Note ",(0,o.kt)("inlineCode",{parentName:"p"},"accessModes")," do not affect actual access and are usually used as labels."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim PVol.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={PVol.yaml}",title:"{PVol.yaml}"},"apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pvvol-1\nspec:\n  capacity:\n    storage: 1Gi\n  accessModes:\n  - ReadWriteMany\n  persistentVolumeReclaimPolicy: Retain\n  nfs:\n    path: /opt/sfw\n    server: k8scp\n    readOnly: false\n")),(0,o.kt)("p",null,"Then we can create the PV and check it was created."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f PVol.yaml\nkubectl get pv\n")),(0,o.kt)("h3",{id:"lab-83---creating-a-persistent-volume-claim-pvc"},"Lab 8.3 - Creating a persistent volume claim (PVC)"),(0,o.kt)("p",null,"First check to see if any PVCs exist."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pvc\n")),(0,o.kt)("p",null,"Now define and then create a new PVC."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim pvc.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={pvc.yaml}",title:"{pvc.yaml}"},"apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc-one\nspec:\n  accessModes:\n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 200Mi\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f pvc.yaml\nkubectl get pvc,pv\n")),(0,o.kt)("p",null,"Notice when you got the PVC, it was 1Gi even though the request was for 200Mi. When you check the PV, you should now see the status as ",(0,o.kt)("inlineCode",{parentName:"p"},"BOUND"),"."),(0,o.kt)("p",null,"Now create a new Deployment that will use the PVC.  We can reuse one of our old deployments. We'll update the name and add a ",(0,o.kt)("inlineCode",{parentName:"p"},"volumeMounts")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"volumes")," section.  The ",(0,o.kt)("inlineCode",{parentName:"p"},"claimName")," in the configuration must match an exist PVC."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cp first.yaml nfs-pod.yaml\nvim nfs-pod.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={nfs-pod.yaml}",title:"{nfs-pod.yaml}"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: "1"\n  generation: 1\n  labels:\n    app: nginx\n  name: nginx-nfs\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: nginx\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        run: nginx\n    spec:\n      containers:\n      - image: nginx\n        imagePullPolicy: Always\n        name: nginx\n        volumeMounts:\n        - name: nfs-vol\n          mountPath: /opt\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      volumes:\n      - name: nfs-vol\n        persistentVolumeClaim:\n          claimName: pvc-one\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\n')),(0,o.kt)("p",null,"Then, create the Pod and check its details. Also check the PVC, you should see it is ",(0,o.kt)("inlineCode",{parentName:"p"},"BOUND"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create -f nfs-pod.yaml\nkubectl get pods\nkubectl describe pod nginx-nfs-<unique ID>\nkubectl get pvc\n")),(0,o.kt)("h3",{id:"lab-84---use-a-resourcequota-to-limit-pvc-count-and-usage"},"Lab 8.4 - Use a ResourceQuota to limit PVC count and usage"),(0,o.kt)("p",null,"Cloud storage often required limiting consumption by certain users because it is so flexible.  For this we will use a ",(0,o.kt)("inlineCode",{parentName:"p"},"ResourceQuota")," to limit the total consumption and the number of PVCs."),(0,o.kt)("p",null,"First let's delete the PV and PVC we created."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pv,pvc\nkubectl delete deploy nginx-nfs\nkubectl delete pvc pvc-one\nkubectl delete pv pvvol-1\n")),(0,o.kt)("p",null,"And then we will create a ",(0,o.kt)("inlineCode",{parentName:"p"},"ResourceQuota"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim storage-quota.yaml\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"title={storage-quota.yaml}",title:"{storage-quota.yaml}"},'apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: storagequota\nspec:\n  hard:\n    persistentvolumeclaims: "10"\n    requests.storage: "500Mi"\n')),(0,o.kt)("p",null,"Then we will create a new namespace, ",(0,o.kt)("inlineCode",{parentName:"p"},"small"),", and describe it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl create ns small\nkubectl describe ns small\n")),(0,o.kt)("p",null,"You'll see it currently has no resource quota or limits. Then recreate the PV and PVC in the new namespace and then apply the new ResourceQuota and describe the namespace again."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small create -f PVol.yaml\nkubectl -n small create -f pvc.yaml\nkubectl -n small create -f storage-quota.yaml\nkubectl describe ns small\n")),(0,o.kt)("p",null,"You should see it now has a ResourceQuota applied on the namespace. Now let's edit the ",(0,o.kt)("inlineCode",{parentName:"p"},"nfs-pod.yaml")," file from earlier and remove the ",(0,o.kt)("inlineCode",{parentName:"p"},"namespace")," line from the metadata, and then recreate it in the new ",(0,o.kt)("inlineCode",{parentName:"p"},"small")," namespace and verify it's running."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vim nfs-pod.yaml\nkubectl -n small create -f nfs-pod.yaml\nkubectl -n small get deploy\nkubectl -n small describe deploy nginx-nfs\n")),(0,o.kt)("p",null,"Then, get the Pods and describe the new Pod to make sure the NFS mounted volume is being used, and then check the quota on the namespace."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small get pod\nkubectl -n small describe pod nginx-nfs-<unique ID>\nkubectl describe ns small\n")),(0,o.kt)("p",null,"Now let's create a 300M file in the /opt/sfw directory and then check the quota on the namespace again."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo dd if=/dev/zero of=/opt/sfw/bigfile bs=1M count=300\nkubectl describe ns small\ndu -h /opt/\n")),(0,o.kt)("p",null,"You should see the quota is unchanged. With the NFS, the size of the shared file does not count against the deployment. Now let's demonstrate what happens when deployments request more than the quota.  First we will delete the deployment, and then the PVC. Then view the PVC."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small get deploy\nkubectl -n small delete deploy nginx-nfs\nkubectl describe ns small\nkubectl -n small get pvc\nkubectl -n small delete pvc pvc-one\nkubectl describe ns small\nkubectl -n small get pv\nkubectl -n small get pv/pvvol-1 -o yaml\n")),(0,o.kt)("p",null,"Notice that the quota didn't change until the PVC was deleted.  Also take note of the ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolumeReclaimPolicy")," of the StorageClass.  This value could be ",(0,o.kt)("inlineCode",{parentName:"p"},"Delete"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Retain"),", or ",(0,o.kt)("inlineCode",{parentName:"p"},"Recycle"),", but manually created PVs default to ",(0,o.kt)("inlineCode",{parentName:"p"},"Retain")," unless set otherwise when creating.  This is the default because it allows for recovery of any data since the storage is kept.  Let's change this from the default."),(0,o.kt)("p",null,"Currently we need to delete the PV and then recreate it, but future development plans on having a deleter plugin. We will then recreate the PV and then use ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl patch")," command to update the policy to ",(0,o.kt)("inlineCode",{parentName:"p"},"Delete"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl delete pv/pvvol-1\ngrep Retain PVol.yaml\nkubectl create -f PVol.yaml\nkubectl patch pv pvvol-1 -p \'{"spec":{"persistentVolumeReclaimPolicy":"Delete"}}\'\nkubectl get pv/pvvol-1\n')),(0,o.kt)("p",null,"Now check the quota on the namespace and then recreate the PVC and check again. You should see the usage go up, even without Pods deployed."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl describe ns small\nkubectl create -n small -f pvc.yaml\nkubectl describe ns small\n")),(0,o.kt)("p",null,"Now we will delete the quota and reduce the capacity to 100Mi."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small get resourcequota\nkubectl -n small delete resourcequota storagequota\nvim storage-quota.yaml\nkubectl -n small create -f storage-quota.yaml\nkubectl describe ns small\n")),(0,o.kt)("p",null,"Note when we describe the namespace to view the limits that the hard limit has already been exceeded. Now we will recreate the Deployment and check the Pods are running. Note that no errors will show."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small create -f nfs-pod.yaml\nkubectl -n small describe deploy/nginx-nfs\nkubectl -n small get po\n")),(0,o.kt)("p",null,"Since we are able to deploy Pods with no error even with the quota exceeded, we will delete the deployment and PVC to see if the Reclaim event takes place."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small delete deploy nginx-nfs\nkubectl -n small delete pvc/pvc-one\nkubectl -n small get pv\n")),(0,o.kt)("p",null,"Notice the ",(0,o.kt)("inlineCode",{parentName:"p"},"STATUS")," is ",(0,o.kt)("inlineCode",{parentName:"p"},"Failed"),".  This has to do with the lack of a deleter volume plugin for NFS. Other storage protocols have a plugin for this."),(0,o.kt)("p",null,"Go ahead and delete the PV and then edit the PV manifest and change the ",(0,o.kt)("inlineCode",{parentName:"p"},"persistentVolumeReclaimPolicy")," to ",(0,o.kt)("inlineCode",{parentName:"p"},"Recycle"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete pv/pvvol-1\nvim PVol.yaml\n")),(0,o.kt)("p",null,"Now we'll add a LimitRange to the new namespace and try to create the PV and PVC again. We can reuse the LimitRange from a previous lab."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small create -f low-resource-range.yaml\nkubectl describe ns small\n")),(0,o.kt)("p",null,"You should see both quota and resource limits applied to the namespace. Now recreate the PV and PVC. Note the PV has a ",(0,o.kt)("inlineCode",{parentName:"p"},"Recycle")," reclaim policy."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small create -f PVol.yaml\nkubectl get pv\nkubectl -n small create -f pvc.yaml\n")),(0,o.kt)("p",null,"You should get an error when creating the PVC.  The quota only takes effect when there is a resource limit in effect."),(0,o.kt)("p",null,"Change the ",(0,o.kt)("inlineCode",{parentName:"p"},"resourcequota")," to increase requested storage to 500Mi under ",(0,o.kt)("inlineCode",{parentName:"p"},"spec.hard.requests.storage")," and then recreate the PVC and Deployment."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small edit resourcequota\nkubectl -n small create -f pvc.yaml\nkubectl -n small create -f nfs-pod.yaml\nkubectl describe ns small\n")),(0,o.kt)("p",null,"Delete the deployment and then view the PV and PVC."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small delete deployment nginx-nfs\nkubectl -n small get pvc,pv\n")),(0,o.kt)("p",null,"Then delete the PVC and view the PV. You should see it is ",(0,o.kt)("inlineCode",{parentName:"p"},"Available"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl -n small delete pvc pvc-one\nkubectl -n small get pv\n")),(0,o.kt)("p",null,"Then finally you can delete the PV."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl delete pv pvvol-1\n")),(0,o.kt)("h2",{id:"knowledge-check"},"Knowledge check"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Applications are ",(0,o.kt)("strong",{parentName:"li"},"not")," required to use persistent storage."),(0,o.kt)("li",{parentName:"ul"},"A Deployment uses a ",(0,o.kt)("strong",{parentName:"li"},"PersistentVolumeClaim"),"."),(0,o.kt)("li",{parentName:"ul"},"The ",(0,o.kt)("inlineCode",{parentName:"li"},"persistentVolumeReclaimPolicy")," determines what happens to the persistent storage upon release."),(0,o.kt)("li",{parentName:"ul"},"Secrets does ",(0,o.kt)("strong",{parentName:"li"},"not")," contain encrypted data."),(0,o.kt)("li",{parentName:"ul"},"ConfigMaps can be created from ",(0,o.kt)("strong",{parentName:"li"},"literal values"),", ",(0,o.kt)("strong",{parentName:"li"},"individual files"),", or ",(0,o.kt)("strong",{parentName:"li"},"many files in a directory"),".")))}u.isMDXComponent=!0},2529:function(e,t,a){t.Z=a.p+"assets/images/ch08-volumes-097df45e32ceb3ddad83983a737d6e34.png"}}]);